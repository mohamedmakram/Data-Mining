{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Airbnb price category prediction"
      ],
      "metadata": {
        "id": "7DHcXT4gPqRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understand the template"
      ],
      "metadata": {
        "id": "TQLaNEawP-EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tasks(1)\n",
        "### What is the experimental protocol used and how was it carried out?\n",
        "\n",
        "\n",
        "*   load data into my workspace then read training and testing data into dataframes. label contains cetegoricies. \n",
        "*   train contains text column (summary) as string, images are grayscale of 2-channel, type is categorical column and price is already encoded\n",
        "\n",
        "*   encode type column, split data into train, validation, resize images\n",
        "into 64x64x2\n",
        "*   tokenize text by turning ezch text into a sequence of integers ( I have created a sequence of 40000 words and enforce the sequence to be of size 100 and pad shorted text with zeros where the is a text of size 9 characters\n",
        "\n",
        "\n",
        "multi-objective task:\n",
        "\n",
        "\n",
        "\n",
        "*   Embeddings are generated for the input text, and the average of the embeddings is computed for each sequence.\n",
        "*   use 2-D convolutional layer and 2-D MaPooling layer then flatten the output \n",
        "\n",
        "\n",
        "*   adding two fully connected layers with softmax as activation function to perform multi-class classification\n",
        "*   using Adam optimaizer with sparse-category-accuracy for accuracy and  sparse-category-crossentropy for loss\n",
        "\n",
        "- using hold-out validation set of .2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b1Ec5RDTRz1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Formulation\n",
        "\n",
        "we try to predict price list(classification problem) instead of actual price (regression problem) by listing the price to three categories representing three intervals (beginner, plus, premium based on the created listing. Respectively we use 0, 1, 2)\n",
        "\n",
        " multi-objective is used to predict the price category along with rental type, multi-modality solution is applied in which we used images along with text summary for training the model  \n",
        "\n",
        " input: text and image data \n",
        "\n",
        " output: predict price range and rental type\n",
        "\n",
        " Data Mining function: extract features from text and images.\n",
        "\n",
        " Challenges: when we try to extract features from text there was a worry about the dimentionality of the dataset (computational power) and when we limitize to a certain number of feature there might be some important feature that would not be used. the text data contain Frensh beside English which make the problem even more harder because you can't treat the two language the same. out-of-vocabulary problem which is words that are not in the training set but appear in the test set. images maybe missleading or with a small dimension so that the model can capture enough information out of it\n",
        "\n",
        " the impact: these problem can bias the model or make it really slow \n",
        "\n",
        " ideal solution: try to find the best combination from text and images that help use produce a model with high accuracy and fast enough to be used in streamline the workflow for Airbnb. \n",
        "\n",
        " \"One of the biggest problems when people prepare to post a new listing on airbnb is, how much should one ask for?\" so if we solve this problem with a model that close enough from what the people expect, we could help strengthen relationships and build trust with consumers renting these properties "
      ],
      "metadata": {
        "id": "OSh2MbjcSBxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tried to overcome my previous problem of less comments and answering the initial questions (What is the experimental protocol ...)"
      ],
      "metadata": {
        "id": "pWaQtDy61v2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First let's download and unzip the dataset\n",
        "! wget https://github.com/CISC-873/Information-2021/releases/download/data/a4.zip\n",
        "\n",
        "! unzip -q a4.zip"
      ],
      "metadata": {
        "id": "cykPU69jg9bF",
        "outputId": "0f32d937-b3b8-4883-e6dc-f5d12d17f6cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-25 03:51:12--  https://github.com/CISC-873/Information-2021/releases/download/data/a4.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/406495726/4d095bba-8b9b-4be4-8738-83f8ff5b0d18?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220325%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220325T035113Z&X-Amz-Expires=300&X-Amz-Signature=3161bff164127c963edf633a347b330709f0593f8abb1b9d0da222cdb9c8542e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=406495726&response-content-disposition=attachment%3B%20filename%3Da4.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-03-25 03:51:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/406495726/4d095bba-8b9b-4be4-8738-83f8ff5b0d18?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220325%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220325T035113Z&X-Amz-Expires=300&X-Amz-Signature=3161bff164127c963edf633a347b330709f0593f8abb1b9d0da222cdb9c8542e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=406495726&response-content-disposition=attachment%3B%20filename%3Da4.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 639078419 (609M) [application/octet-stream]\n",
            "Saving to: ‘a4.zip’\n",
            "\n",
            "a4.zip              100%[===================>] 609.47M  95.3MB/s    in 6.9s    \n",
            "\n",
            "2022-03-25 03:51:20 (88.9 MB/s) - ‘a4.zip’ saved [639078419/639078419]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from ast import literal_eval"
      ],
      "metadata": {
        "id": "8W0vl9cw7hQp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# read the dataset\n",
        "train = pd.read_csv('train_xy.csv')\n",
        "test = pd.read_csv('test_x.csv')"
      ],
      "metadata": {
        "id": "uC0rbbwxg9-o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "5PdrRuUFld8M",
        "outputId": "8e75037d-0333-4953-c352-cc6205bb185a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             summary            image  \\\n",
              "0  Spacious, sunny and cozy modern apartment in t...  img_train/0.jpg   \n",
              "1  Located in one of the most vibrant and accessi...  img_train/1.jpg   \n",
              "2  Logement coquet et douillet à 10 minutes du ce...  img_train/2.jpg   \n",
              "3  Beautiful and spacious (1076 sc ft, / 100 mc) ...  img_train/3.jpg   \n",
              "4  Très grand appartement ''rustique'' et très ag...  img_train/4.jpg   \n",
              "\n",
              "        type  price  \n",
              "0  Apartment      1  \n",
              "1  Apartment      0  \n",
              "2  Apartment      1  \n",
              "3  Apartment      1  \n",
              "4  Apartment      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed2bbb0d-09fb-402b-9822-07ae5ab43a01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>image</th>\n",
              "      <th>type</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Spacious, sunny and cozy modern apartment in t...</td>\n",
              "      <td>img_train/0.jpg</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Located in one of the most vibrant and accessi...</td>\n",
              "      <td>img_train/1.jpg</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logement coquet et douillet à 10 minutes du ce...</td>\n",
              "      <td>img_train/2.jpg</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beautiful and spacious (1076 sc ft, / 100 mc) ...</td>\n",
              "      <td>img_train/3.jpg</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Très grand appartement ''rustique'' et très ag...</td>\n",
              "      <td>img_train/4.jpg</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed2bbb0d-09fb-402b-9822-07ae5ab43a01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed2bbb0d-09fb-402b-9822-07ae5ab43a01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed2bbb0d-09fb-402b-9822-07ae5ab43a01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Word Cloud](https://stackoverflow.com/questions/16645799/how-to-create-a-word-cloud-from-a-corpus-in-python)"
      ],
      "metadata": {
        "id": "qrY490p1KswT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "stopwords = set(STOPWORDS)\n",
        "# Create and generate a word cloud image\n",
        "cloud_positives = WordCloud(stopwords = stopwords, background_color='white').generate(str(train['summary']))\n",
        " \n",
        "# Display the generated wordcloud image\n",
        "plt.imshow(cloud_positives, interpolation='bilinear') \n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Don't forget to show the final image\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "TFzhLAC9qcb0",
        "outputId": "23960460-87c9-44da-c5df-a45739b61cff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Exploration and Preprocessing"
      ],
      "metadata": {
        "id": "27H6Jn46ZPRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's encode the type column. After, lets split the dataset into training set and testing set."
      ],
      "metadata": {
        "id": "aDg7Eqif7Ee7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train['type'] = train['type'].astype('category').cat.codes\n",
        "train_df, test_df = train_test_split(train, test_size=.2, random_state = 42)"
      ],
      "metadata": {
        "id": "WRP_DHHG6EmP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(train.summary.str.len())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBTP7REFkRIr",
        "outputId": "0eabee14-1aff-4389-b999-4eb676602315"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train.summary.str.len() == 1000.0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "GFReVHjxkqql",
        "outputId": "fafe7b7e-4ee0-4228-b589-e15ad63392f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                summary               image  \\\n",
              "643   GÎTE PATRIMONIAL DU XIX SIÈCLE Situé directeme...   img_train/643.jpg   \n",
              "683   Located in the heart of Plateau Mont-Royal, we...   img_train/683.jpg   \n",
              "1099  Grand appartement situé sur l'Ile de Montréal....  img_train/1099.jpg   \n",
              "1691  quiet and clean in Downtown!  Perfect place fo...  img_train/1691.jpg   \n",
              "1724  You will enjoy sleeping in our soft and comfor...  img_train/1724.jpg   \n",
              "2373  Conversation is seamless in the open concept g...  img_train/2373.jpg   \n",
              "2998  Imagine a fully renovated apartment in one of ...  img_train/2998.jpg   \n",
              "4038  Imagine a fully renovated apartment in one of ...  img_train/4039.jpg   \n",
              "4097  Conversation is seamless in the living room. P...  img_train/4099.jpg   \n",
              "5885  You will enjoy sleeping in our soft and comfor...  img_train/5888.jpg   \n",
              "6045  Private room with lockable door in a spacious ...  img_train/6048.jpg   \n",
              "6391  Two rooms to bed with queen bed, wakes up in m...  img_train/6394.jpg   \n",
              "6742  Private room with lockable door in a spacious ...  img_train/6745.jpg   \n",
              "6784  Imagine two fully renovated apartments in one ...  img_train/6787.jpg   \n",
              "\n",
              "      type  price  \n",
              "643     18      1  \n",
              "683     10      2  \n",
              "1099     1      0  \n",
              "1691    20      0  \n",
              "1724     1      0  \n",
              "2373     1      0  \n",
              "2998     1      0  \n",
              "4038     1      1  \n",
              "4097     1      0  \n",
              "5885     1      0  \n",
              "6045     1      1  \n",
              "6391     1      2  \n",
              "6742     1      2  \n",
              "6784     1      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b90f7eb-44c4-4af9-aaad-5563bb29b64c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>image</th>\n",
              "      <th>type</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>643</th>\n",
              "      <td>GÎTE PATRIMONIAL DU XIX SIÈCLE Situé directeme...</td>\n",
              "      <td>img_train/643.jpg</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>Located in the heart of Plateau Mont-Royal, we...</td>\n",
              "      <td>img_train/683.jpg</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099</th>\n",
              "      <td>Grand appartement situé sur l'Ile de Montréal....</td>\n",
              "      <td>img_train/1099.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1691</th>\n",
              "      <td>quiet and clean in Downtown!  Perfect place fo...</td>\n",
              "      <td>img_train/1691.jpg</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1724</th>\n",
              "      <td>You will enjoy sleeping in our soft and comfor...</td>\n",
              "      <td>img_train/1724.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>Conversation is seamless in the open concept g...</td>\n",
              "      <td>img_train/2373.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>Imagine a fully renovated apartment in one of ...</td>\n",
              "      <td>img_train/2998.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4038</th>\n",
              "      <td>Imagine a fully renovated apartment in one of ...</td>\n",
              "      <td>img_train/4039.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097</th>\n",
              "      <td>Conversation is seamless in the living room. P...</td>\n",
              "      <td>img_train/4099.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5885</th>\n",
              "      <td>You will enjoy sleeping in our soft and comfor...</td>\n",
              "      <td>img_train/5888.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6045</th>\n",
              "      <td>Private room with lockable door in a spacious ...</td>\n",
              "      <td>img_train/6048.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6391</th>\n",
              "      <td>Two rooms to bed with queen bed, wakes up in m...</td>\n",
              "      <td>img_train/6394.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6742</th>\n",
              "      <td>Private room with lockable door in a spacious ...</td>\n",
              "      <td>img_train/6745.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6784</th>\n",
              "      <td>Imagine two fully renovated apartments in one ...</td>\n",
              "      <td>img_train/6787.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b90f7eb-44c4-4af9-aaad-5563bb29b64c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b90f7eb-44c4-4af9-aaad-5563bb29b64c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b90f7eb-44c4-4af9-aaad-5563bb29b64c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "language detection "
      ],
      "metadata": {
        "id": "6pITC03XQFcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfaexMQ_M7Ov",
        "outputId": "05cece71-49a2-454d-e766-b969a534f407"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=f3fa426b3296b146a8ccdb74b6dd226f5b0dfc8b4e0d5524c055a7cc635231ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(train.summary.str.len())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRDoBKKNkX5Y",
        "outputId": "d4e823d1-eb9c-4840-f07c-592b6211c3ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train.summary.str.len() == 9.0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "xe9hVN3zkf_N",
        "outputId": "463e401d-f981-4c34-ee13-541619d2710a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        summary               image  type  price\n",
              "6345  Très joli  img_train/6348.jpg     1      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c327661a-e590-4c08-bece-43e4517fe44a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>image</th>\n",
              "      <th>type</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6345</th>\n",
              "      <td>Très joli</td>\n",
              "      <td>img_train/6348.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c327661a-e590-4c08-bece-43e4517fe44a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c327661a-e590-4c08-bece-43e4517fe44a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c327661a-e590-4c08-bece-43e4517fe44a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6rCGYulM_FC2",
        "outputId": "1621547b-883c-4cb7-ef5d-b4fb793c66ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                summary               image  \\\n",
              "1513  This one bedroom is located in the Village 10 ...  img_train/1513.jpg   \n",
              "216   *présentement en rénovation des photos seront ...   img_train/216.jpg   \n",
              "4379  C'est un réel plaisir de vous recevoir dans no...  img_train/4381.jpg   \n",
              "5214  Bel appartement, emplacement idéal!  À 1mn du ...  img_train/5216.jpg   \n",
              "421   Près du marché Jean-Talon et de plusieurs bout...   img_train/421.jpg   \n",
              "\n",
              "      type  price  \n",
              "1513    18      0  \n",
              "216      1      0  \n",
              "4379     1      1  \n",
              "5214     1      0  \n",
              "421      1      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26c9bffb-d1d0-4e4b-bbac-f4ebbbd40e9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>image</th>\n",
              "      <th>type</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>This one bedroom is located in the Village 10 ...</td>\n",
              "      <td>img_train/1513.jpg</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>*présentement en rénovation des photos seront ...</td>\n",
              "      <td>img_train/216.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4379</th>\n",
              "      <td>C'est un réel plaisir de vous recevoir dans no...</td>\n",
              "      <td>img_train/4381.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5214</th>\n",
              "      <td>Bel appartement, emplacement idéal!  À 1mn du ...</td>\n",
              "      <td>img_train/5216.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>Près du marché Jean-Talon et de plusieurs bout...</td>\n",
              "      <td>img_train/421.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26c9bffb-d1d0-4e4b-bbac-f4ebbbd40e9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26c9bffb-d1d0-4e4b-bbac-f4ebbbd40e9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26c9bffb-d1d0-4e4b-bbac-f4ebbbd40e9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ty09wZeG_IF8",
        "outputId": "be15013c-336b-4d15-a83e-97c8b60c44f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                summary               image  \\\n",
              "683   Located in the heart of Plateau Mont-Royal, we...   img_train/683.jpg   \n",
              "1964  Private room and full access to completely equ...  img_train/1964.jpg   \n",
              "4149  Perfect for family with baby! This 2 bedroom i...  img_train/4151.jpg   \n",
              "3378                                                NaN  img_train/3379.jpg   \n",
              "7272  Centrally located, this apartment is prone to ...  img_train/7276.jpg   \n",
              "\n",
              "      type  price  \n",
              "683     10      2  \n",
              "1964     1      0  \n",
              "4149     1      0  \n",
              "3378    17      0  \n",
              "7272     1      2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc09d8e0-d95f-47ce-9e79-2b9b7fc36b43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>image</th>\n",
              "      <th>type</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>Located in the heart of Plateau Mont-Royal, we...</td>\n",
              "      <td>img_train/683.jpg</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>Private room and full access to completely equ...</td>\n",
              "      <td>img_train/1964.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4149</th>\n",
              "      <td>Perfect for family with baby! This 2 bedroom i...</td>\n",
              "      <td>img_train/4151.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3378</th>\n",
              "      <td>NaN</td>\n",
              "      <td>img_train/3379.jpg</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7272</th>\n",
              "      <td>Centrally located, this apartment is prone to ...</td>\n",
              "      <td>img_train/7276.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc09d8e0-d95f-47ce-9e79-2b9b7fc36b43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc09d8e0-d95f-47ce-9e79-2b9b7fc36b43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc09d8e0-d95f-47ce-9e79-2b9b7fc36b43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We have image and text data.\n",
        "\n",
        "Image data: resize\n",
        "\n",
        "Text data: tokenization and converting to integer IDs"
      ],
      "metadata": {
        "id": "GOE1KhTrWcSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess image data\n",
        "import os\n",
        "\n",
        "def load_image(file):\n",
        "    try:\n",
        "        image = Image.open(\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64))\n",
        "        arr = np.array(image)\n",
        "    except:\n",
        "        arr = np.zeros((64, 64, 2))\n",
        "    return arr\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_train_image = np.array([load_image(i) for i in tqdm(train_df.image)])\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_train_text = train_df.summary.astype('str')\n",
        "\n",
        "# get price \n",
        "y_train_price = train_df.price\n",
        "\n",
        "# get type\n",
        "y_train_type = train_df['type']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2bba01d9147d486e94acdd4fc4819d11",
            "59428197821243bca96420891aeddec3",
            "018a23b301254fc882f578191308e2ca",
            "b720f43fd7eb4de683dbb20e62456296",
            "293654a4a79542fcafd8e06c82a72606",
            "d9f2c9cdec614e4f927d2d952a541618",
            "67f40f780bbc41eaa5d910108fdfee42",
            "236012a2084349a7882094631fae1d90",
            "5847317f659c4fb490bd36907f634b4d",
            "3f1b72c8632e41f8bd3d26e80791256f",
            "35ecc7d7fefb44bd9e637d2b06d60431"
          ]
        },
        "id": "80XSakNdPvsF",
        "outputId": "4a3840de-cf5e-4b2b-eb23-013b6c78ced2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6101 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bba01d9147d486e94acdd4fc4819d11"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_image = np.array([load_image(i) for i in tqdm(train.image)])\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_train_text = train.summary.astype('str')\n",
        "\n",
        "# get price \n",
        "y_train_price = train.price\n",
        "\n",
        "# get type\n",
        "y_train_type = train['type']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b6f35e5ad25945f6bb0330fd2b8a4ca6",
            "2de7f8ff2cbe4143aab02086dafe969c",
            "668daa5188ac435798c2555e2491baf7",
            "65df93313bb740c39edda684914e462f",
            "370b6bb362214e97a6d3284f7581be59",
            "c253f2f96c54446a8cd27dea21c85fab",
            "b5e039419ae24d0abf98896869365aba",
            "866821b385dd4df485cbd9adaa0d2297",
            "249f8217e1d94144b22de31e2c0e0864",
            "1d2cc6c7f5924a6e8a943b011ab15c59",
            "cd161faf40634164b1863bc979cbff2a"
          ]
        },
        "id": "7cQTn5Z4012q",
        "outputId": "afbe4083-d0c7-43ad-e6a2-1cfd60591cb6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6f35e5ad25945f6bb0330fd2b8a4ca6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# length of unique values at price and type\n",
        "len_price = len(train.price.unique())\n",
        "len_type = len(train['type'].unique())"
      ],
      "metadata": {
        "id": "-9oTyfzcI2xJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the sentiment, including polarity and subjectivity"
      ],
      "metadata": {
        "id": "rZQQMqzLhBuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check image loading\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train_image[199, :, :, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "Pi43177LBy5V",
        "outputId": "2ab02a07-0bca-4f2d-df82-08182c6ec9ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8e53a710d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)\n",
        "\n",
        "num_words:\tthe maximum number of words to keep, based on word frequency\n",
        "\n",
        "fit_on_texts: Updates internal vocabulary based on a list of texts.\n"
      ],
      "metadata": {
        "id": "UX23NTsegy20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess text data\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000\n",
        "max_len = 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(x_train_text)\n",
        "\n",
        "\n",
        "def _preprocess(list_of_text):\n",
        "    return pad_sequences(\n",
        "        tokenizer.texts_to_sequences(list_of_text),\n",
        "        maxlen=max_len,\n",
        "        padding='post',\n",
        "    )\n",
        "    \n",
        "\n",
        "# padding is done inside: \n",
        "x_train_text_id = _preprocess(x_train_text)\n",
        "\n",
        "print(x_train_text_id.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyMp6irOCyj9",
        "outputId": "52dc3f39-08f9-4c8c-bc0c-63ea7b6ed9c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7627, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use the tokenizer to convert IDs to words.\n",
        "pprint(tokenizer.sequences_to_texts(x_train_text_id[:10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P0NzWR8DFGs",
        "outputId": "8312af5d-eb03-4623-8da4-813854b5acd6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this one bedroom is located in the village 10 min walk from downtown open '\n",
            " 'space with a calm bedroom located in the semi building of an historical '\n",
            " 'building the apartment sleeps comfortably 4 people there is on queen sized '\n",
            " 'bed and a super confortable sofa bed linens and towels are provided you will '\n",
            " 'have access to a fully equipped and very well stocked kitchen free wifi is '\n",
            " 'provided',\n",
            " \"présentement en rénovation des photos seront bientôt ajouter besoin d'un \"\n",
            " 'espace pour venir vous reposer',\n",
            " \"c'est un réel plaisir de vous recevoir dans notre confortable logement \"\n",
            " \"lumineux spacieux et soigné au 2ième étage d'un duplex un espace simple et \"\n",
            " 'sans prétention un environnement calme et reposant un quartier sympathique '\n",
            " 'très familial directement sur le coin station bixi pistes cyclables et '\n",
            " 'autobus métros jean talon et fabre à environ 10 minutes à pied marché jean '\n",
            " 'talon 1 km et la petite italie à environ 15 minutes à pied le centre ville '\n",
            " '15 20 minutes en voiture ou en métro',\n",
            " 'bel appartement emplacement idéal à 1mn du métro mont royal épiceries et '\n",
            " 'supermarchés à proximité chambre avec fenêtres donnant sur ruelle arrière '\n",
            " 'avec blacon pas de bruit quartier chaleureux avec beaucoup de commerces '\n",
            " 'restaurants bars et cafés sympas je pourrais vous laisser une liste '\n",
            " \"d'adresse si vous ne connaissez pas la ville au plaisir de vous accueillir \"\n",
            " 'ici',\n",
            " 'près du marché jean talon et de plusieurs boutiques le logement offre un '\n",
            " 'emplacement idéal sur l’île de montréal la station de métro fabre est à 6 '\n",
            " \"minutes de marche de l'appartement il est donc très facile de se déplacer a \"\n",
            " \"travers la ville en transport en commun l'université se situe à 15 minutes \"\n",
            " 'du logement et on se rend au centre ville en 25 minutes ce logement est '\n",
            " 'idéal pour un couple ou une personne seule et offre toutes les commodités '\n",
            " 'nécessaire pour un séjour à montréal confortable',\n",
            " 'thank you for looking at my listing i would love to host you in this '\n",
            " 'beautifully renovated private bachelor with free parking private entrance '\n",
            " 'near st lawrence river bike paths downtown 25 min by car 40 min by public '\n",
            " \"transport i'm an experienced host on airbnb and have welcomed travelers from \"\n",
            " 'all around the world for the past 3 years it would be my pleasure to have '\n",
            " 'you as my next guest',\n",
            " 'the apartment is ideal to enjoy the vibrant upbeat city life of montreal and '\n",
            " 'privacy at the same time brings to life the beauty of mont royal and the '\n",
            " 'pace of downtown the refreshing view from balcony is adds fun to your coffee '\n",
            " 'drink my place is close to downtown place des arts rue st catherine rue st '\n",
            " 'denis rue st laurent things i bet you will love the location the '\n",
            " 'neighbourhood and the people perfect for family andgroup of friends to enjoy '\n",
            " 'togetherness',\n",
            " 'this amazing apartment bright and well decorated on the 2d and last floor is '\n",
            " 'the perfect spot for your stay in montreal very spacious it is in the heart '\n",
            " 'of the plateau mont royal minutes away from the metro station grocery store '\n",
            " 'bars and restaurants the bedrooms and the private deck are in the back what '\n",
            " 'ensures the quietness of a cozy home when you need to rest and relax an '\n",
            " 'office room with printer allows to work comfortably an outside parking spot '\n",
            " 'is available 5mn away',\n",
            " 'énorme chambre centenaire avec beaucoup de cachet qui comprend un lit queen '\n",
            " 'le wi fi une tv un bureau de travail un accès à un ordinateur du rangement '\n",
            " 'et un frigo privé la casa est un très grand appartement au rez de chaussé '\n",
            " 'situé à 200m du métro sherbrooke à 1km du parc lafontaine et du square st '\n",
            " \"louis en plein coeur du plateau mont royal c'est en étant accueillants et \"\n",
            " \"sociables qu'il nous fera plaisir de vous accueillir et de s'assurer de \"\n",
            " 'votre confort lors de votre séjour',\n",
            " 'i really enjoy hosting and care for you to have an amazing stay i welcome '\n",
            " 'you in a beautiful sunny apartment fully renovated this year the place '\n",
            " 'offers you a great stay in a very welcoming and warm surrounding located on '\n",
            " 'a calm street close to the downtown area you will find in a 10minutes '\n",
            " 'distance a bixi rental bike station nice parks metro station grocery stores '\n",
            " 'coffees and restaurant']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('total words in the dictionary:', tokenizer.num_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-8tSAngDR-L",
        "outputId": "4f2bcbd9-b52c-4837-ef5f-bce651a01c6e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total words in the dictionary: 40000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Model"
      ],
      "metadata": {
        "id": "-7KHSlYPISpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# here we have two inputs. one for image and the other for text.\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "# simple average of embedding. you can change it to anything else as needed\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "averaged = tf.reduce_mean(embedded, axis=1)\n",
        "\n",
        "\n",
        "# image part \n",
        "# simple conv2d. you can change it to anything else as needed\n",
        "cov = Conv2D(32, (16, 16))(in_image)\n",
        "pl = MaxPool2D((16, 16))(cov)\n",
        "flattened = Flatten()(pl)\n",
        "\n",
        "\n",
        "# fusion - combinig both\n",
        "fused = tf.concat([averaged, flattened], axis=-1)\n",
        "\n",
        "# multi-task learning (each is a multi-class classification)\n",
        "# one dense layer for each task\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused)\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused)\n",
        "\n",
        "\n",
        "# define model input/output using keys.\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# compile model with optimizer, loss values for each task, loss \n",
        "# weights for each task.\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypmZPm86IRjW",
        "outputId": "082cbf72-e9b9-4045-cfe9-30882c4c79a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 49, 49, 32)   16416       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 3, 3, 32)     0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpLambd  (None, 100)         0           ['embedding[0][0]']              \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 288)          0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 388)          0           ['tf.math.reduce_mean[0][0]',    \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1167        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           9336        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,026,919\n",
            "Trainable params: 4,026,919\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n",
        "Based on the training/validation performance, you can adjust the epochs to be trained. Early stoping is watching the validation loss on genre prediction (assuming that it is the main task we would like to perform)"
      ],
      "metadata": {
        "id": "owXdu6YcJhyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'price': y_train_price,\n",
        "        'type': y_train_type,\n",
        "    },\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_genre_loss', patience=5, )\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKNrJ2aaIRtu",
        "outputId": "399708e9-15ec-46fa-cd6f-3b7daaf95d5f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 26.8685 - price_loss: 22.3856 - type_loss: 31.3515 - price_sparse_categorical_accuracy: 0.5006 - type_sparse_categorical_accuracy: 0.5883WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 61s 195ms/step - loss: 26.8685 - price_loss: 22.3856 - type_loss: 31.3515 - price_sparse_categorical_accuracy: 0.5006 - type_sparse_categorical_accuracy: 0.5883 - val_loss: 13.8207 - val_price_loss: 5.6074 - val_type_loss: 22.0341 - val_price_sparse_categorical_accuracy: 0.5872 - val_type_sparse_categorical_accuracy: 0.4521\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 10.3117 - price_loss: 7.3491 - type_loss: 13.2744 - price_sparse_categorical_accuracy: 0.5172 - type_sparse_categorical_accuracy: 0.5873WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 57s 186ms/step - loss: 10.3117 - price_loss: 7.3491 - type_loss: 13.2744 - price_sparse_categorical_accuracy: 0.5172 - type_sparse_categorical_accuracy: 0.5873 - val_loss: 5.9379 - val_price_loss: 3.6083 - val_type_loss: 8.2675 - val_price_sparse_categorical_accuracy: 0.4636 - val_type_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 7.1782 - price_loss: 5.4787 - type_loss: 8.8777 - price_sparse_categorical_accuracy: 0.5334 - type_sparse_categorical_accuracy: 0.6006WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 189ms/step - loss: 7.1782 - price_loss: 5.4787 - type_loss: 8.8777 - price_sparse_categorical_accuracy: 0.5334 - type_sparse_categorical_accuracy: 0.6006 - val_loss: 4.9303 - val_price_loss: 3.8100 - val_type_loss: 6.0506 - val_price_sparse_categorical_accuracy: 0.5217 - val_type_sparse_categorical_accuracy: 0.7101\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 6.3046 - price_loss: 4.5426 - type_loss: 8.0666 - price_sparse_categorical_accuracy: 0.5475 - type_sparse_categorical_accuracy: 0.6082WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 57s 187ms/step - loss: 6.3046 - price_loss: 4.5426 - type_loss: 8.0666 - price_sparse_categorical_accuracy: 0.5475 - type_sparse_categorical_accuracy: 0.6082 - val_loss: 5.6917 - val_price_loss: 4.7766 - val_type_loss: 6.6068 - val_price_sparse_categorical_accuracy: 0.6102 - val_type_sparse_categorical_accuracy: 0.5495\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 4.2563 - price_loss: 3.3116 - type_loss: 5.2010 - price_sparse_categorical_accuracy: 0.5650 - type_sparse_categorical_accuracy: 0.6225WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 57s 187ms/step - loss: 4.2563 - price_loss: 3.3116 - type_loss: 5.2010 - price_sparse_categorical_accuracy: 0.5650 - type_sparse_categorical_accuracy: 0.6225 - val_loss: 5.4180 - val_price_loss: 4.2106 - val_type_loss: 6.6254 - val_price_sparse_categorical_accuracy: 0.5839 - val_type_sparse_categorical_accuracy: 0.4693\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 6.6816 - price_loss: 4.5551 - type_loss: 8.8081 - price_sparse_categorical_accuracy: 0.5674 - type_sparse_categorical_accuracy: 0.6135WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 59s 193ms/step - loss: 6.6816 - price_loss: 4.5551 - type_loss: 8.8081 - price_sparse_categorical_accuracy: 0.5674 - type_sparse_categorical_accuracy: 0.6135 - val_loss: 6.5858 - val_price_loss: 3.7704 - val_type_loss: 9.4012 - val_price_sparse_categorical_accuracy: 0.5455 - val_type_sparse_categorical_accuracy: 0.6986\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 8.9950 - price_loss: 7.1980 - type_loss: 10.7919 - price_sparse_categorical_accuracy: 0.5867 - type_sparse_categorical_accuracy: 0.6119WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 190ms/step - loss: 8.9950 - price_loss: 7.1980 - type_loss: 10.7919 - price_sparse_categorical_accuracy: 0.5867 - type_sparse_categorical_accuracy: 0.6119 - val_loss: 15.8373 - val_price_loss: 10.6506 - val_type_loss: 21.0240 - val_price_sparse_categorical_accuracy: 0.4177 - val_type_sparse_categorical_accuracy: 0.7314\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 13.5611 - price_loss: 8.3282 - type_loss: 18.7939 - price_sparse_categorical_accuracy: 0.5672 - type_sparse_categorical_accuracy: 0.6088WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 60s 196ms/step - loss: 13.5611 - price_loss: 8.3282 - type_loss: 18.7939 - price_sparse_categorical_accuracy: 0.5672 - type_sparse_categorical_accuracy: 0.6088 - val_loss: 8.6866 - val_price_loss: 6.6674 - val_type_loss: 10.7058 - val_price_sparse_categorical_accuracy: 0.5078 - val_type_sparse_categorical_accuracy: 0.5119\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 6.6162 - price_loss: 4.1602 - type_loss: 9.0721 - price_sparse_categorical_accuracy: 0.6119 - type_sparse_categorical_accuracy: 0.6430WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 191ms/step - loss: 6.6162 - price_loss: 4.1602 - type_loss: 9.0721 - price_sparse_categorical_accuracy: 0.6119 - type_sparse_categorical_accuracy: 0.6430 - val_loss: 6.4716 - val_price_loss: 4.0229 - val_type_loss: 8.9203 - val_price_sparse_categorical_accuracy: 0.5880 - val_type_sparse_categorical_accuracy: 0.4578\n",
            "Epoch 10/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 9.5437 - price_loss: 5.6000 - type_loss: 13.4873 - price_sparse_categorical_accuracy: 0.6141 - type_sparse_categorical_accuracy: 0.6352WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 190ms/step - loss: 9.5437 - price_loss: 5.6000 - type_loss: 13.4873 - price_sparse_categorical_accuracy: 0.6141 - type_sparse_categorical_accuracy: 0.6352 - val_loss: 6.3043 - val_price_loss: 4.6451 - val_type_loss: 7.9636 - val_price_sparse_categorical_accuracy: 0.5389 - val_type_sparse_categorical_accuracy: 0.5979\n",
            "Epoch 11/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 5.8115 - price_loss: 3.8167 - type_loss: 7.8063 - price_sparse_categorical_accuracy: 0.6355 - type_sparse_categorical_accuracy: 0.6477WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 190ms/step - loss: 5.8115 - price_loss: 3.8167 - type_loss: 7.8063 - price_sparse_categorical_accuracy: 0.6355 - type_sparse_categorical_accuracy: 0.6477 - val_loss: 6.0004 - val_price_loss: 4.6557 - val_type_loss: 7.3450 - val_price_sparse_categorical_accuracy: 0.4406 - val_type_sparse_categorical_accuracy: 0.6609\n",
            "Epoch 12/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 8.0815 - price_loss: 4.9280 - type_loss: 11.2349 - price_sparse_categorical_accuracy: 0.6180 - type_sparse_categorical_accuracy: 0.6408WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 191ms/step - loss: 8.0815 - price_loss: 4.9280 - type_loss: 11.2349 - price_sparse_categorical_accuracy: 0.6180 - type_sparse_categorical_accuracy: 0.6408 - val_loss: 8.9252 - val_price_loss: 6.7526 - val_type_loss: 11.0979 - val_price_sparse_categorical_accuracy: 0.6388 - val_type_sparse_categorical_accuracy: 0.6577\n",
            "Epoch 13/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 7.5317 - price_loss: 4.6885 - type_loss: 10.3749 - price_sparse_categorical_accuracy: 0.6391 - type_sparse_categorical_accuracy: 0.6496WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 190ms/step - loss: 7.5317 - price_loss: 4.6885 - type_loss: 10.3749 - price_sparse_categorical_accuracy: 0.6391 - type_sparse_categorical_accuracy: 0.6496 - val_loss: 5.4612 - val_price_loss: 3.6871 - val_type_loss: 7.2352 - val_price_sparse_categorical_accuracy: 0.5856 - val_type_sparse_categorical_accuracy: 0.6552\n",
            "Epoch 14/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 5.8664 - price_loss: 3.1423 - type_loss: 8.5905 - price_sparse_categorical_accuracy: 0.6830 - type_sparse_categorical_accuracy: 0.6740WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 190ms/step - loss: 5.8664 - price_loss: 3.1423 - type_loss: 8.5905 - price_sparse_categorical_accuracy: 0.6830 - type_sparse_categorical_accuracy: 0.6740 - val_loss: 6.8603 - val_price_loss: 4.1866 - val_type_loss: 9.5340 - val_price_sparse_categorical_accuracy: 0.5610 - val_type_sparse_categorical_accuracy: 0.5987\n",
            "Epoch 15/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 4.1623 - price_loss: 2.7703 - type_loss: 5.5542 - price_sparse_categorical_accuracy: 0.6816 - type_sparse_categorical_accuracy: 0.6848WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 189ms/step - loss: 4.1623 - price_loss: 2.7703 - type_loss: 5.5542 - price_sparse_categorical_accuracy: 0.6816 - type_sparse_categorical_accuracy: 0.6848 - val_loss: 4.9090 - val_price_loss: 4.1520 - val_type_loss: 5.6659 - val_price_sparse_categorical_accuracy: 0.6339 - val_type_sparse_categorical_accuracy: 0.6855\n",
            "Epoch 16/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 5.5939 - price_loss: 3.3302 - type_loss: 7.8576 - price_sparse_categorical_accuracy: 0.6961 - type_sparse_categorical_accuracy: 0.6775WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 189ms/step - loss: 5.5939 - price_loss: 3.3302 - type_loss: 7.8576 - price_sparse_categorical_accuracy: 0.6961 - type_sparse_categorical_accuracy: 0.6775 - val_loss: 5.1257 - val_price_loss: 3.6265 - val_type_loss: 6.6248 - val_price_sparse_categorical_accuracy: 0.6282 - val_type_sparse_categorical_accuracy: 0.7355\n",
            "Epoch 17/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 4.8916 - price_loss: 2.9189 - type_loss: 6.8642 - price_sparse_categorical_accuracy: 0.7064 - type_sparse_categorical_accuracy: 0.6785WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 57s 188ms/step - loss: 4.8916 - price_loss: 2.9189 - type_loss: 6.8642 - price_sparse_categorical_accuracy: 0.7064 - type_sparse_categorical_accuracy: 0.6785 - val_loss: 5.2461 - val_price_loss: 3.6863 - val_type_loss: 6.8059 - val_price_sparse_categorical_accuracy: 0.5872 - val_type_sparse_categorical_accuracy: 0.7101\n",
            "Epoch 18/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 16.7433 - price_loss: 9.5438 - type_loss: 23.9428 - price_sparse_categorical_accuracy: 0.6514 - type_sparse_categorical_accuracy: 0.6545WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 57s 187ms/step - loss: 16.7433 - price_loss: 9.5438 - type_loss: 23.9428 - price_sparse_categorical_accuracy: 0.6514 - type_sparse_categorical_accuracy: 0.6545 - val_loss: 7.8795 - val_price_loss: 4.3587 - val_type_loss: 11.4002 - val_price_sparse_categorical_accuracy: 0.6061 - val_type_sparse_categorical_accuracy: 0.6044\n",
            "Epoch 19/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 10.8037 - price_loss: 4.8622 - type_loss: 16.7453 - price_sparse_categorical_accuracy: 0.6656 - type_sparse_categorical_accuracy: 0.6588WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 57s 188ms/step - loss: 10.8037 - price_loss: 4.8622 - type_loss: 16.7453 - price_sparse_categorical_accuracy: 0.6656 - type_sparse_categorical_accuracy: 0.6588 - val_loss: 7.9750 - val_price_loss: 5.1184 - val_type_loss: 10.8315 - val_price_sparse_categorical_accuracy: 0.5242 - val_type_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 20/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 5.8526 - price_loss: 2.7078 - type_loss: 8.9974 - price_sparse_categorical_accuracy: 0.7232 - type_sparse_categorical_accuracy: 0.7016WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 58s 190ms/step - loss: 5.8526 - price_loss: 2.7078 - type_loss: 8.9974 - price_sparse_categorical_accuracy: 0.7232 - type_sparse_categorical_accuracy: 0.7016 - val_loss: 5.8858 - val_price_loss: 3.8536 - val_type_loss: 7.9181 - val_price_sparse_categorical_accuracy: 0.6192 - val_type_sparse_categorical_accuracy: 0.6577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing (Testing)\n",
        "Here we use the trained tokenizer to pre-process the testing set."
      ],
      "metadata": {
        "id": "yHDXU0vJPwm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reda test data\n",
        "test = pd.read_csv('test_x.csv')"
      ],
      "metadata": {
        "id": "syhGcfpfP4nw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading images:\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(test.image)])\n",
        "\n",
        "# loading overview: (force convert some of the non-string cell to string)\n",
        "x_test_text = _preprocess(test.summary.astype('str'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "aafead4ec66145c7aaebc62392d9b033",
            "9178aea6abc0464ea57d4c3ad238bb36",
            "3f83ae07308345ceb839087398b55663",
            "6e0b10fc091c468d84d36e9163560cd7",
            "0888aadbf917498890fab3b5e6130e67",
            "405ac1bc6dab4146b184b375635c1b75",
            "786b0ddc35714c36b8ec1976d6c655e6",
            "058403f64c1d4749bf8ceaa59dc0092b",
            "3ba146b343aa42498a5bcf3faf261ba2",
            "61ef24ab89524ce48c45a203f5b4e2e3",
            "770c9957c0914ea1b8a4ef4c6edaf00f"
          ]
        },
        "id": "a8KZQyloIRxM",
        "outputId": "1110e3bb-3977-44a0-fc48-3914bf547cd3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aafead4ec66145c7aaebc62392d9b033"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predition\n",
        "We can use the model to predict the testing samples."
      ],
      "metadata": {
        "id": "MSl306yQQKHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "y_predict = model.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted = y_predict['price']\n",
        "print(price_predicted)\n",
        "\n",
        "# categories\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1)\n",
        "print(price_category_predicted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6I7CUOJQF0-",
        "outputId": "6bb46e2f-6da2-4a90-dda2-98fe830f6cfb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.9980706e-01 1.6090480e-04 3.2011812e-05]\n",
            " [7.4188375e-01 2.5806314e-01 5.3134132e-05]\n",
            " [9.9997151e-01 1.7375540e-05 1.1035804e-05]\n",
            " ...\n",
            " [5.5362976e-01 4.4637027e-01 5.5186056e-09]\n",
            " [9.9999988e-01 1.6181529e-07 1.7773852e-12]\n",
            " [9.9874604e-01 1.2539541e-03 2.4637256e-11]]\n",
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(\n",
        "    {'id': test.id,\n",
        "     'price': price_category_predicted}\n",
        ").to_csv('sample_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "ONS7_9doQU2H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qSGUvJ1-bZGG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 2\n",
        "###Text inputs. a LSTM layer\n",
        "\n",
        "thoughts and observations for trial 1: it gave me a good result 0.60896 on Kaggle\n",
        "\n",
        "plan for trial 2: using LSTM instead of reduce_mean"
      ],
      "metadata": {
        "id": "wkzFqd0xmTXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unsing LSTM layer\n",
        "from tensorflow.keras.layers import LSTM\n",
        "# here we have two inputs. one for image and the other for text.\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "# simple average of embedding. you can change it to anything else as needed\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "\n",
        "# adding LSTM layer after embedding layer and\n",
        "# this is the only difference than the reduce_mean that\n",
        "# has been used on the lab\n",
        "lstm = LSTM(50)(embedded)\n",
        "\n",
        "\n",
        "# image part \n",
        "# simple conv2d. you can change it to anything else as needed\n",
        "cov = Conv2D(32, (16, 16))(in_image)\n",
        "pl = MaxPool2D((16, 16))(cov)\n",
        "flattened = Flatten()(pl)\n",
        "\n",
        "\n",
        "# fusion - combinig both\n",
        "fused = tf.concat([lstm, flattened], axis=-1)\n",
        "\n",
        "# multi-task learning (each is a multi-class classification)\n",
        "# one dense layer for each task\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused)\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused)\n",
        "\n",
        "\n",
        "# define model input/output using keys.\n",
        "lstm_model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# compile model with optimizer, loss values for each task, loss \n",
        "# weights for each task.\n",
        "lstm_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqqrMKA8mSlR",
        "outputId": "251cfc32-54ac-433a-ef49-9d1e58eacf07"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 49, 49, 32)   16416       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 100, 100)     4000000     ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 3, 3, 32)    0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 50)           30200       ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 288)          0           ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " tf.concat_1 (TFOpLambda)       (None, 338)          0           ['lstm[0][0]',                   \n",
            "                                                                  'flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1017        ['tf.concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           8136        ['tf.concat_1[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,055,769\n",
            "Trainable params: 4,055,769\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = lstm_model.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'price': y_train_price,\n",
        "        'type': y_train_type,\n",
        "    },\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, )\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuwmHiFTzVrQ",
        "outputId": "b62ed5a3-1f80-4b1e-8d65-7638583acc6e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "305/305 [==============================] - 69s 218ms/step - loss: 23.2783 - price_loss: 20.7882 - type_loss: 25.7685 - price_sparse_categorical_accuracy: 0.5037 - type_sparse_categorical_accuracy: 0.5920 - val_loss: 11.0742 - val_price_loss: 6.0807 - val_type_loss: 16.0677 - val_price_sparse_categorical_accuracy: 0.4472 - val_type_sparse_categorical_accuracy: 0.2170\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 64s 210ms/step - loss: 7.8642 - price_loss: 5.9064 - type_loss: 9.8221 - price_sparse_categorical_accuracy: 0.5113 - type_sparse_categorical_accuracy: 0.5969 - val_loss: 8.1314 - val_price_loss: 3.8990 - val_type_loss: 12.3638 - val_price_sparse_categorical_accuracy: 0.5004 - val_type_sparse_categorical_accuracy: 0.2768\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 64s 211ms/step - loss: 6.7924 - price_loss: 5.1045 - type_loss: 8.4804 - price_sparse_categorical_accuracy: 0.5207 - type_sparse_categorical_accuracy: 0.5992 - val_loss: 7.8534 - val_price_loss: 5.8635 - val_type_loss: 9.8433 - val_price_sparse_categorical_accuracy: 0.5356 - val_type_sparse_categorical_accuracy: 0.6962\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 65s 212ms/step - loss: 5.1403 - price_loss: 4.0410 - type_loss: 6.2396 - price_sparse_categorical_accuracy: 0.5209 - type_sparse_categorical_accuracy: 0.6020 - val_loss: 6.1085 - val_price_loss: 4.6120 - val_type_loss: 7.6049 - val_price_sparse_categorical_accuracy: 0.5274 - val_type_sparse_categorical_accuracy: 0.6618\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 64s 210ms/step - loss: 6.0353 - price_loss: 4.5870 - type_loss: 7.4835 - price_sparse_categorical_accuracy: 0.5182 - type_sparse_categorical_accuracy: 0.6031 - val_loss: 5.8148 - val_price_loss: 4.7342 - val_type_loss: 6.8955 - val_price_sparse_categorical_accuracy: 0.3743 - val_type_sparse_categorical_accuracy: 0.6978\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 64s 210ms/step - loss: 5.2981 - price_loss: 4.3101 - type_loss: 6.2861 - price_sparse_categorical_accuracy: 0.5311 - type_sparse_categorical_accuracy: 0.6148 - val_loss: 5.7810 - val_price_loss: 3.5101 - val_type_loss: 8.0520 - val_price_sparse_categorical_accuracy: 0.5152 - val_type_sparse_categorical_accuracy: 0.7355\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 64s 211ms/step - loss: 8.8098 - price_loss: 7.3113 - type_loss: 10.3083 - price_sparse_categorical_accuracy: 0.5289 - type_sparse_categorical_accuracy: 0.5986 - val_loss: 9.9730 - val_price_loss: 5.3774 - val_type_loss: 14.5686 - val_price_sparse_categorical_accuracy: 0.5291 - val_type_sparse_categorical_accuracy: 0.6290\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 65s 215ms/step - loss: 18.6904 - price_loss: 11.1094 - type_loss: 26.2714 - price_sparse_categorical_accuracy: 0.5162 - type_sparse_categorical_accuracy: 0.5920 - val_loss: 9.9324 - val_price_loss: 7.1582 - val_type_loss: 12.7066 - val_price_sparse_categorical_accuracy: 0.4586 - val_type_sparse_categorical_accuracy: 0.5987\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - 72s 235ms/step - loss: 7.0404 - price_loss: 4.4934 - type_loss: 9.5874 - price_sparse_categorical_accuracy: 0.5574 - type_sparse_categorical_accuracy: 0.6119 - val_loss: 11.6947 - val_price_loss: 5.5801 - val_type_loss: 17.8093 - val_price_sparse_categorical_accuracy: 0.4029 - val_type_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 10/20\n",
            "305/305 [==============================] - 70s 228ms/step - loss: 6.9966 - price_loss: 4.5695 - type_loss: 9.4237 - price_sparse_categorical_accuracy: 0.5553 - type_sparse_categorical_accuracy: 0.6088 - val_loss: 6.0852 - val_price_loss: 4.2632 - val_type_loss: 7.9071 - val_price_sparse_categorical_accuracy: 0.4595 - val_type_sparse_categorical_accuracy: 0.5242\n",
            "Epoch 11/20\n",
            "305/305 [==============================] - 67s 220ms/step - loss: 4.9681 - price_loss: 3.5125 - type_loss: 6.4238 - price_sparse_categorical_accuracy: 0.5570 - type_sparse_categorical_accuracy: 0.6232 - val_loss: 5.3911 - val_price_loss: 3.3974 - val_type_loss: 7.3847 - val_price_sparse_categorical_accuracy: 0.5471 - val_type_sparse_categorical_accuracy: 0.5962\n",
            "Epoch 12/20\n",
            "305/305 [==============================] - 66s 218ms/step - loss: 4.1796 - price_loss: 3.1126 - type_loss: 5.2465 - price_sparse_categorical_accuracy: 0.5734 - type_sparse_categorical_accuracy: 0.6264 - val_loss: 5.5254 - val_price_loss: 3.8101 - val_type_loss: 7.2406 - val_price_sparse_categorical_accuracy: 0.4881 - val_type_sparse_categorical_accuracy: 0.6044\n",
            "Epoch 13/20\n",
            "305/305 [==============================] - 66s 216ms/step - loss: 4.0878 - price_loss: 3.0500 - type_loss: 5.1255 - price_sparse_categorical_accuracy: 0.5695 - type_sparse_categorical_accuracy: 0.6273 - val_loss: 6.4980 - val_price_loss: 4.1459 - val_type_loss: 8.8501 - val_price_sparse_categorical_accuracy: 0.4046 - val_type_sparse_categorical_accuracy: 0.3366\n",
            "Epoch 14/20\n",
            "305/305 [==============================] - 65s 213ms/step - loss: 4.3264 - price_loss: 3.1128 - type_loss: 5.5399 - price_sparse_categorical_accuracy: 0.5682 - type_sparse_categorical_accuracy: 0.6203 - val_loss: 5.6445 - val_price_loss: 4.7625 - val_type_loss: 6.5266 - val_price_sparse_categorical_accuracy: 0.5962 - val_type_sparse_categorical_accuracy: 0.5569\n",
            "Epoch 15/20\n",
            "305/305 [==============================] - 65s 214ms/step - loss: 17.6412 - price_loss: 12.0058 - type_loss: 23.2765 - price_sparse_categorical_accuracy: 0.5410 - type_sparse_categorical_accuracy: 0.6092 - val_loss: 47.1311 - val_price_loss: 19.0289 - val_type_loss: 75.2334 - val_price_sparse_categorical_accuracy: 0.1859 - val_type_sparse_categorical_accuracy: 0.0581\n",
            "Epoch 16/20\n",
            "305/305 [==============================] - 65s 213ms/step - loss: 24.7959 - price_loss: 12.7523 - type_loss: 36.8396 - price_sparse_categorical_accuracy: 0.5346 - type_sparse_categorical_accuracy: 0.5932 - val_loss: 7.5826 - val_price_loss: 4.2454 - val_type_loss: 10.9198 - val_price_sparse_categorical_accuracy: 0.5315 - val_type_sparse_categorical_accuracy: 0.6970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "y_predict_lstm = lstm_model.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_lstm = y_predict_lstm['price']\n",
        "print(price_predicted)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_lstm = np.argmax(price_predicted_lstm, axis=1)\n",
        "print(price_category_predicted_lstm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EAnB1edq2qE",
        "outputId": "447e0757-b5a5-4b99-a69d-6eb2cd70244a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.9980706e-01 1.6090480e-04 3.2011812e-05]\n",
            " [7.4188375e-01 2.5806314e-01 5.3134132e-05]\n",
            " [9.9997151e-01 1.7375540e-05 1.1035804e-05]\n",
            " ...\n",
            " [5.5362976e-01 4.4637027e-01 5.5186056e-09]\n",
            " [9.9999988e-01 1.6181529e-07 1.7773852e-12]\n",
            " [9.9874604e-01 1.2539541e-03 2.4637256e-11]]\n",
            "[0 0 1 ... 2 2 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(\n",
        "    {'id': test.id,\n",
        "     'price': price_category_predicted_lstm}\n",
        ").to_csv('sample_submission_lstm.csv', index=False)"
      ],
      "metadata": {
        "id": "TXHhfKSp0Yaa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 3: Using GRU\n",
        "thoughts and observations for trial 2 :LSTM had improved my accuracy on Kaggle from 0.60896 to 0.61304\n",
        "\n",
        "plan for trial 3:\n",
        "using GRU layer instead of LSTM\n"
      ],
      "metadata": {
        "id": "zN3oWVF1969L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unsing GRU layer\n",
        "from tensorflow.keras.layers import GRU\n",
        "# here we have two inputs. one for image and the other for text.\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "# simple average of embedding. you can change it to anything else as needed\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "\n",
        "# adding GRU layer after embedding layer and\n",
        "# this is the only difference than the LSTM\n",
        "gru = GRU(20)(embedded)\n",
        "\n",
        "\n",
        "# image part \n",
        "# simple conv2d. you can change it to anything else as needed\n",
        "cov = Conv2D(32, (16, 16))(in_image)\n",
        "pl = MaxPool2D((16, 16))(cov)\n",
        "flattened = Flatten()(pl)\n",
        "\n",
        "\n",
        "# fusion - combinig both\n",
        "fused = tf.concat([gru, flattened], axis=-1)\n",
        "\n",
        "# multi-task learning (each is a multi-class classification)\n",
        "# one dense layer for each task\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused)\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused)\n",
        "\n",
        "\n",
        "# define model input/output using keys.\n",
        "gru_model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# compile model with optimizer, loss values for each task, loss \n",
        "# weights for each task.\n",
        "gru_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "gru_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8vdhGpD9_3v",
        "outputId": "7a219784-d885-4594-9c1d-68f17cbcf5a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 49, 49, 32)   16416       ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 100, 100)     4000000     ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 32)    0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 20)           7320        ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 288)          0           ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " tf.concat_2 (TFOpLambda)       (None, 308)          0           ['gru[0][0]',                    \n",
            "                                                                  'flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            927         ['tf.concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           7416        ['tf.concat_2[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,032,079\n",
            "Trainable params: 4,032,079\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_gru = gru_model.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'price': y_train_price,\n",
        "        'type': y_train_type,\n",
        "    },\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, )\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlkV6ubT_Saf",
        "outputId": "c2c9113c-1207-4fdf-ea70-fc328a4bea6e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "305/305 [==============================] - 65s 205ms/step - loss: 30.7806 - price_loss: 24.3972 - type_loss: 37.1639 - price_sparse_categorical_accuracy: 0.5008 - type_sparse_categorical_accuracy: 0.5926 - val_loss: 13.4196 - val_price_loss: 7.2424 - val_type_loss: 19.5969 - val_price_sparse_categorical_accuracy: 0.5430 - val_type_sparse_categorical_accuracy: 0.6896\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 62s 202ms/step - loss: 11.8800 - price_loss: 8.7881 - type_loss: 14.9719 - price_sparse_categorical_accuracy: 0.5080 - type_sparse_categorical_accuracy: 0.5916 - val_loss: 9.2296 - val_price_loss: 6.9045 - val_type_loss: 11.5547 - val_price_sparse_categorical_accuracy: 0.3767 - val_type_sparse_categorical_accuracy: 0.6241\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 65s 212ms/step - loss: 6.5558 - price_loss: 5.2357 - type_loss: 7.8759 - price_sparse_categorical_accuracy: 0.5082 - type_sparse_categorical_accuracy: 0.5965 - val_loss: 6.9835 - val_price_loss: 4.9595 - val_type_loss: 9.0075 - val_price_sparse_categorical_accuracy: 0.5102 - val_type_sparse_categorical_accuracy: 0.6658\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 63s 206ms/step - loss: 7.1059 - price_loss: 5.6502 - type_loss: 8.5616 - price_sparse_categorical_accuracy: 0.5221 - type_sparse_categorical_accuracy: 0.5980 - val_loss: 5.3130 - val_price_loss: 3.7632 - val_type_loss: 6.8627 - val_price_sparse_categorical_accuracy: 0.5504 - val_type_sparse_categorical_accuracy: 0.6241\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 63s 207ms/step - loss: 5.8553 - price_loss: 4.9315 - type_loss: 6.7790 - price_sparse_categorical_accuracy: 0.5277 - type_sparse_categorical_accuracy: 0.6039 - val_loss: 5.0250 - val_price_loss: 4.0120 - val_type_loss: 6.0380 - val_price_sparse_categorical_accuracy: 0.5536 - val_type_sparse_categorical_accuracy: 0.6290\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 66s 215ms/step - loss: 11.5146 - price_loss: 9.1178 - type_loss: 13.9115 - price_sparse_categorical_accuracy: 0.5555 - type_sparse_categorical_accuracy: 0.6033 - val_loss: 9.0131 - val_price_loss: 5.8877 - val_type_loss: 12.1385 - val_price_sparse_categorical_accuracy: 0.6036 - val_type_sparse_categorical_accuracy: 0.2580\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 63s 206ms/step - loss: 6.0264 - price_loss: 4.1124 - type_loss: 7.9405 - price_sparse_categorical_accuracy: 0.6027 - type_sparse_categorical_accuracy: 0.6064 - val_loss: 6.8612 - val_price_loss: 4.9417 - val_type_loss: 8.7807 - val_price_sparse_categorical_accuracy: 0.5717 - val_type_sparse_categorical_accuracy: 0.6593\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 62s 203ms/step - loss: 4.7262 - price_loss: 3.2632 - type_loss: 6.1893 - price_sparse_categorical_accuracy: 0.6539 - type_sparse_categorical_accuracy: 0.6160 - val_loss: 7.2298 - val_price_loss: 5.5477 - val_type_loss: 8.9119 - val_price_sparse_categorical_accuracy: 0.5184 - val_type_sparse_categorical_accuracy: 0.5864\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - 62s 203ms/step - loss: 4.7924 - price_loss: 3.1170 - type_loss: 6.4677 - price_sparse_categorical_accuracy: 0.6885 - type_sparse_categorical_accuracy: 0.6156 - val_loss: 5.5609 - val_price_loss: 4.4705 - val_type_loss: 6.6512 - val_price_sparse_categorical_accuracy: 0.6208 - val_type_sparse_categorical_accuracy: 0.6970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "y_predict_gru = gru_model.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_gru = y_predict_gru['price']\n",
        "print(price_predicted_gru)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_gru = np.argmax(price_predicted_gru, axis=1)\n",
        "print(price_category_predicted_gru)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vksKOzYl_pdy",
        "outputId": "370debb1-06ac-4969-869e-1e57a61bc8d6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0000000e+00 6.5546873e-11 2.2030779e-16]\n",
            " [9.9999988e-01 2.4080574e-11 1.6855358e-07]\n",
            " [9.9864393e-01 1.3543651e-03 1.6525905e-06]\n",
            " ...\n",
            " [1.0000000e+00 2.9979109e-11 1.4673656e-11]\n",
            " [1.5062705e-07 9.9999988e-01 4.2193683e-08]\n",
            " [9.7623038e-01 2.3768267e-02 1.3842160e-06]]\n",
            "[0 0 0 ... 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(\n",
        "    {'id': test.id,\n",
        "     'price': price_category_predicted_gru}\n",
        ").to_csv('sample_submission_gru.csv', index=False)"
      ],
      "metadata": {
        "id": "N0yFuCyw_6t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CjhxUGRKG0I1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 4: Bi-directional Recurrent Layers\n",
        "\n",
        "thoughts and observations for trial 3 : LSTM had improved my accuracy on Kaggle from 0.61304 to 0.61847\n",
        "\n",
        "plan for trial 4: adding Bidirectional to GRU layer\n",
        "\n"
      ],
      "metadata": {
        "id": "TCwMn5teHHo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import bidirectional\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "# here we have two inputs. one for image and the other for text.\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "# simple average of embedding. you can change it to anything else as needed\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "\n",
        "# adding GRU layer after embedding layer and\n",
        "# this is the only difference than the LSTM\n",
        "bi_gru = Bidirectional(GRU(20))(embedded)\n",
        "\n",
        "\n",
        "# image part \n",
        "# simple conv2d. you can change it to anything else as needed\n",
        "cov = Conv2D(32, (16, 16))(in_image)\n",
        "pl = MaxPool2D((16, 16))(cov)\n",
        "flattened = Flatten()(pl)\n",
        "\n",
        "\n",
        "# fusion - combinig both\n",
        "fused = tf.concat([bi_gru, flattened], axis=-1)\n",
        "\n",
        "# multi-task learning (each is a multi-class classification)\n",
        "# one dense layer for each task\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused)\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused)\n",
        "\n",
        "\n",
        "# define model input/output using keys.\n",
        "bi_gru_model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# compile model with optimizer, loss values for each task, loss \n",
        "# weights for each task.\n",
        "bi_gru_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "bi_gru_model.summary()"
      ],
      "metadata": {
        "id": "dEhkzXzXHlYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99fc349-06ac-4187-db29-e6c4c12a4b1c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 49, 49, 32)   16416       ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 100, 100)     4000000     ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 32)    0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 40)           14640       ['embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 288)          0           ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " tf.concat_3 (TFOpLambda)       (None, 328)          0           ['bidirectional[0][0]',          \n",
            "                                                                  'flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            987         ['tf.concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           7896        ['tf.concat_3[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,039,939\n",
            "Trainable params: 4,039,939\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = bi_gru_model.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'price': y_train_price,\n",
        "        'type': y_train_type,\n",
        "    },\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_genre_loss', patience=5, )\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLVTinWsZZ9s",
        "outputId": "a151abb0-ec48-4169-a3a1-af688247dca2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 26.3666 - price_loss: 18.1483 - type_loss: 34.5849 - price_sparse_categorical_accuracy: 0.5105 - type_sparse_categorical_accuracy: 0.5861WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 33s 69ms/step - loss: 26.3666 - price_loss: 18.1483 - type_loss: 34.5849 - price_sparse_categorical_accuracy: 0.5105 - type_sparse_categorical_accuracy: 0.5861 - val_loss: 10.6660 - val_price_loss: 8.0934 - val_type_loss: 13.2386 - val_price_sparse_categorical_accuracy: 0.6110 - val_type_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 10.8041 - price_loss: 7.1637 - type_loss: 14.4445 - price_sparse_categorical_accuracy: 0.5467 - type_sparse_categorical_accuracy: 0.5990WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 10.8041 - price_loss: 7.1637 - type_loss: 14.4445 - price_sparse_categorical_accuracy: 0.5467 - type_sparse_categorical_accuracy: 0.5990 - val_loss: 9.6920 - val_price_loss: 6.1921 - val_type_loss: 13.1919 - val_price_sparse_categorical_accuracy: 0.4333 - val_type_sparse_categorical_accuracy: 0.6994\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 6.0309 - price_loss: 3.9243 - type_loss: 8.1375 - price_sparse_categorical_accuracy: 0.6014 - type_sparse_categorical_accuracy: 0.6105WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 6.0309 - price_loss: 3.9243 - type_loss: 8.1375 - price_sparse_categorical_accuracy: 0.6014 - type_sparse_categorical_accuracy: 0.6105 - val_loss: 6.5712 - val_price_loss: 3.8888 - val_type_loss: 9.2536 - val_price_sparse_categorical_accuracy: 0.5020 - val_type_sparse_categorical_accuracy: 0.7101\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 5.5272 - price_loss: 3.5596 - type_loss: 7.4948 - price_sparse_categorical_accuracy: 0.6342 - type_sparse_categorical_accuracy: 0.6102WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 5.5272 - price_loss: 3.5596 - type_loss: 7.4948 - price_sparse_categorical_accuracy: 0.6342 - type_sparse_categorical_accuracy: 0.6102 - val_loss: 7.0330 - val_price_loss: 5.6635 - val_type_loss: 8.4026 - val_price_sparse_categorical_accuracy: 0.6355 - val_type_sparse_categorical_accuracy: 0.3890\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 4.4402 - price_loss: 3.0355 - type_loss: 5.8448 - price_sparse_categorical_accuracy: 0.6508 - type_sparse_categorical_accuracy: 0.6260WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 4.4402 - price_loss: 3.0355 - type_loss: 5.8448 - price_sparse_categorical_accuracy: 0.6508 - type_sparse_categorical_accuracy: 0.6260 - val_loss: 5.7962 - val_price_loss: 3.7785 - val_type_loss: 7.8139 - val_price_sparse_categorical_accuracy: 0.6003 - val_type_sparse_categorical_accuracy: 0.4013\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 5.8601 - price_loss: 3.9906 - type_loss: 7.7295 - price_sparse_categorical_accuracy: 0.6586 - type_sparse_categorical_accuracy: 0.6168WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 5.8601 - price_loss: 3.9906 - type_loss: 7.7295 - price_sparse_categorical_accuracy: 0.6586 - type_sparse_categorical_accuracy: 0.6168 - val_loss: 29.8838 - val_price_loss: 34.8854 - val_type_loss: 24.8823 - val_price_sparse_categorical_accuracy: 0.6298 - val_type_sparse_categorical_accuracy: 0.7232\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 5.6815 - price_loss: 3.9160 - type_loss: 7.4471 - price_sparse_categorical_accuracy: 0.6785 - type_sparse_categorical_accuracy: 0.6244WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 66ms/step - loss: 5.6815 - price_loss: 3.9160 - type_loss: 7.4471 - price_sparse_categorical_accuracy: 0.6785 - type_sparse_categorical_accuracy: 0.6244 - val_loss: 8.8873 - val_price_loss: 5.4981 - val_type_loss: 12.2766 - val_price_sparse_categorical_accuracy: 0.6437 - val_type_sparse_categorical_accuracy: 0.7510\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 5.0461 - price_loss: 3.1683 - type_loss: 6.9239 - price_sparse_categorical_accuracy: 0.7086 - type_sparse_categorical_accuracy: 0.6285WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 5.0461 - price_loss: 3.1683 - type_loss: 6.9239 - price_sparse_categorical_accuracy: 0.7086 - type_sparse_categorical_accuracy: 0.6285 - val_loss: 9.1347 - val_price_loss: 4.8265 - val_type_loss: 13.4428 - val_price_sparse_categorical_accuracy: 0.6077 - val_type_sparse_categorical_accuracy: 0.7207\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 4.4825 - price_loss: 2.8219 - type_loss: 6.1432 - price_sparse_categorical_accuracy: 0.7178 - type_sparse_categorical_accuracy: 0.6541WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 4.4825 - price_loss: 2.8219 - type_loss: 6.1432 - price_sparse_categorical_accuracy: 0.7178 - type_sparse_categorical_accuracy: 0.6541 - val_loss: 5.4743 - val_price_loss: 4.9121 - val_type_loss: 6.0364 - val_price_sparse_categorical_accuracy: 0.6020 - val_type_sparse_categorical_accuracy: 0.6429\n",
            "Epoch 10/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 5.6445 - price_loss: 3.2973 - type_loss: 7.9916 - price_sparse_categorical_accuracy: 0.7213 - type_sparse_categorical_accuracy: 0.6477WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 5.6445 - price_loss: 3.2973 - type_loss: 7.9916 - price_sparse_categorical_accuracy: 0.7213 - type_sparse_categorical_accuracy: 0.6477 - val_loss: 8.1131 - val_price_loss: 6.3822 - val_type_loss: 9.8440 - val_price_sparse_categorical_accuracy: 0.5520 - val_type_sparse_categorical_accuracy: 0.7494\n",
            "Epoch 11/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 4.0490 - price_loss: 2.7269 - type_loss: 5.3711 - price_sparse_categorical_accuracy: 0.7516 - type_sparse_categorical_accuracy: 0.6689WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 4.0490 - price_loss: 2.7269 - type_loss: 5.3711 - price_sparse_categorical_accuracy: 0.7516 - type_sparse_categorical_accuracy: 0.6689 - val_loss: 5.9138 - val_price_loss: 4.9333 - val_type_loss: 6.8943 - val_price_sparse_categorical_accuracy: 0.6077 - val_type_sparse_categorical_accuracy: 0.6552\n",
            "Epoch 12/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 4.6408 - price_loss: 2.9127 - type_loss: 6.3690 - price_sparse_categorical_accuracy: 0.7426 - type_sparse_categorical_accuracy: 0.6697WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 4.6408 - price_loss: 2.9127 - type_loss: 6.3690 - price_sparse_categorical_accuracy: 0.7426 - type_sparse_categorical_accuracy: 0.6697 - val_loss: 10.3818 - val_price_loss: 6.7152 - val_type_loss: 14.0484 - val_price_sparse_categorical_accuracy: 0.6290 - val_type_sparse_categorical_accuracy: 0.5659\n",
            "Epoch 13/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 16.7874 - price_loss: 8.5328 - type_loss: 25.0420 - price_sparse_categorical_accuracy: 0.7168 - type_sparse_categorical_accuracy: 0.6295WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 16.7874 - price_loss: 8.5328 - type_loss: 25.0420 - price_sparse_categorical_accuracy: 0.7168 - type_sparse_categorical_accuracy: 0.6295 - val_loss: 16.3953 - val_price_loss: 8.0607 - val_type_loss: 24.7298 - val_price_sparse_categorical_accuracy: 0.5495 - val_type_sparse_categorical_accuracy: 0.5135\n",
            "Epoch 14/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 13.3015 - price_loss: 6.2251 - type_loss: 20.3780 - price_sparse_categorical_accuracy: 0.7307 - type_sparse_categorical_accuracy: 0.6645WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 13.3015 - price_loss: 6.2251 - type_loss: 20.3780 - price_sparse_categorical_accuracy: 0.7307 - type_sparse_categorical_accuracy: 0.6645 - val_loss: 9.2134 - val_price_loss: 8.1450 - val_type_loss: 10.2817 - val_price_sparse_categorical_accuracy: 0.5938 - val_type_sparse_categorical_accuracy: 0.6904\n",
            "Epoch 15/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 7.3764 - price_loss: 4.0542 - type_loss: 10.6986 - price_sparse_categorical_accuracy: 0.7840 - type_sparse_categorical_accuracy: 0.7107WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 7.3764 - price_loss: 4.0542 - type_loss: 10.6986 - price_sparse_categorical_accuracy: 0.7840 - type_sparse_categorical_accuracy: 0.7107 - val_loss: 8.1826 - val_price_loss: 7.3895 - val_type_loss: 8.9757 - val_price_sparse_categorical_accuracy: 0.6061 - val_type_sparse_categorical_accuracy: 0.6495\n",
            "Epoch 16/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 4.4830 - price_loss: 2.1808 - type_loss: 6.7853 - price_sparse_categorical_accuracy: 0.8154 - type_sparse_categorical_accuracy: 0.7369WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 4.4830 - price_loss: 2.1808 - type_loss: 6.7853 - price_sparse_categorical_accuracy: 0.8154 - type_sparse_categorical_accuracy: 0.7369 - val_loss: 13.2927 - val_price_loss: 8.3995 - val_type_loss: 18.1860 - val_price_sparse_categorical_accuracy: 0.5364 - val_type_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 17/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 3.1689 - price_loss: 1.7592 - type_loss: 4.5787 - price_sparse_categorical_accuracy: 0.8270 - type_sparse_categorical_accuracy: 0.7660WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 3.1689 - price_loss: 1.7592 - type_loss: 4.5787 - price_sparse_categorical_accuracy: 0.8270 - type_sparse_categorical_accuracy: 0.7660 - val_loss: 7.2779 - val_price_loss: 6.3823 - val_type_loss: 8.1734 - val_price_sparse_categorical_accuracy: 0.5930 - val_type_sparse_categorical_accuracy: 0.7305\n",
            "Epoch 18/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 4.5194 - price_loss: 2.2539 - type_loss: 6.7848 - price_sparse_categorical_accuracy: 0.8160 - type_sparse_categorical_accuracy: 0.7426WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 4.5194 - price_loss: 2.2539 - type_loss: 6.7848 - price_sparse_categorical_accuracy: 0.8160 - type_sparse_categorical_accuracy: 0.7426 - val_loss: 7.7559 - val_price_loss: 7.6061 - val_type_loss: 7.9058 - val_price_sparse_categorical_accuracy: 0.5569 - val_type_sparse_categorical_accuracy: 0.6806\n",
            "Epoch 19/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 3.7010 - price_loss: 2.1162 - type_loss: 5.2857 - price_sparse_categorical_accuracy: 0.8295 - type_sparse_categorical_accuracy: 0.7637WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 3.7010 - price_loss: 2.1162 - type_loss: 5.2857 - price_sparse_categorical_accuracy: 0.8295 - type_sparse_categorical_accuracy: 0.7637 - val_loss: 8.0055 - val_price_loss: 7.8111 - val_type_loss: 8.1998 - val_price_sparse_categorical_accuracy: 0.6011 - val_type_sparse_categorical_accuracy: 0.6650\n",
            "Epoch 20/20\n",
            "305/305 [==============================] - ETA: 0s - loss: 2.4332 - price_loss: 1.4990 - type_loss: 3.3675 - price_sparse_categorical_accuracy: 0.8568 - type_sparse_categorical_accuracy: 0.7928WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "305/305 [==============================] - 20s 65ms/step - loss: 2.4332 - price_loss: 1.4990 - type_loss: 3.3675 - price_sparse_categorical_accuracy: 0.8568 - type_sparse_categorical_accuracy: 0.7928 - val_loss: 8.4009 - val_price_loss: 8.0146 - val_type_loss: 8.7871 - val_price_sparse_categorical_accuracy: 0.5561 - val_type_sparse_categorical_accuracy: 0.6495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "y_predict_bi_gru = bi_gru_model.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_bi_gru = y_predict_bi_gru['price']\n",
        "print(price_predicted_bi_gru)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_bi_gru = np.argmax(price_predicted_bi_gru, axis=1)\n",
        "print(price_category_predicted_bi_gru)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k44ZDHKZgdj",
        "outputId": "91dfa00a-858f-4bf9-a480-d17b1f9c5c6b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.5681640e-12 9.9999797e-01 1.9714150e-06]\n",
            " [1.0000000e+00 4.0867777e-15 5.2932017e-31]\n",
            " [1.0000000e+00 9.2256480e-10 3.2671671e-12]\n",
            " ...\n",
            " [9.9999452e-01 5.4832885e-06 6.8625225e-19]\n",
            " [9.9983358e-01 1.6398073e-04 2.3285188e-06]\n",
            " [2.4678728e-03 9.9751931e-01 1.2741266e-05]]\n",
            "[1 0 0 ... 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(\n",
        "    {'id': test.id,\n",
        "     'price': price_category_predicted_bi_gru}\n",
        ").to_csv('sample_submission_bi_gru.csv', index=False)"
      ],
      "metadata": {
        "id": "zEYDA62-Zjgi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 5\n",
        "\n",
        "thoughts and observations for trial 4: it performed worse the accuracy went from 0.61847 down to 0.58315  \n",
        "plan for trial 5: MultiHeadAttention beside Bidirectional and GRU"
      ],
      "metadata": {
        "id": "kCIod46_hKsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MultiHeadAttention\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Rescaling\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "# simple average of embedding. you can change it to anything else as needed\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "\n",
        "# adding GRU layer after embedding layer and\n",
        "# this is the only difference than the LSTM\n",
        "attention = MultiHeadAttention(num_heads=2, key_dim=2)(embedded, embedded)\n",
        "bi_lstm = Bidirectional(GRU(50, recurrent_regularizer='l2'))(attention)\n",
        "\n",
        "\n",
        "scaling = Rescaling(1./127.5, offset=-1)(in_image) # rescaling\n",
        "pl = GlobalAveragePooling2D()(scaling) # global average pooling, pretty much the same as flattening\n",
        "do = Dropout(0.2)(pl) # dropout at a rate of 20%\n",
        "fl = Flatten()(do)\n",
        "\n",
        "# image part \n",
        "# simple conv2d. you can change it to anything else as needed\n",
        "cov = Conv2D(32, (16, 16))(in_image)\n",
        "pl = MaxPool2D((16, 16))(cov)\n",
        "flattened = Flatten()(pl)\n",
        "\n",
        "\n",
        "# fusion - combinig both\n",
        "fused = tf.concat([bi_lstm, flattened], axis=-1)\n",
        "\n",
        "# multi-task learning (each is a multi-class classification)\n",
        "# one dense layer for each task\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused)\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused)\n",
        "\n",
        "\n",
        "# define model input/output using keys.\n",
        "bi_lstm_model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# compile model with optimizer, loss values for each task, loss \n",
        "# weights for each task.\n",
        "bi_lstm_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "bi_lstm_model.summary()"
      ],
      "metadata": {
        "id": "o2yuafitEKxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MultiHeadAttention\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Rescaling\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "# simple average of embedding. you can change it to anything else as needed\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "\n",
        "# adding GRU layer after embedding layer and\n",
        "# this is the only difference than the LSTM\n",
        "attention = MultiHeadAttention(num_heads=2, key_dim=2)(embedded, embedded)\n",
        "bi_lstm = Bidirectional(GRU(50, recurrent_regularizer='l2'))(attention)\n",
        "\n",
        "# image part \n",
        "# simple conv2d. you can change it to anything else as needed\n",
        "cov = Conv2D(32, (16, 16))(in_image)\n",
        "pl = MaxPool2D((16, 16))(cov)\n",
        "flattened = Flatten()(pl)\n",
        "\n",
        "\n",
        "# fusion - combinig both\n",
        "fused = tf.concat([bi_lstm, flattened], axis=-1)\n",
        "\n",
        "# multi-task learning (each is a multi-class classification)\n",
        "# one dense layer for each task\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused)\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused)\n",
        "\n",
        "\n",
        "# define model input/output using keys.\n",
        "bi_lstm_model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# compile model with optimizer, loss values for each task, loss \n",
        "# weights for each task.\n",
        "bi_lstm_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "bi_lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY-XCnDWrGXN",
        "outputId": "e8d7f5f3-ef91-4709-8808-8607dfa81b6b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_17 (InputLayer)          [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " input_18 (InputLayer)          [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)        (None, 100, 100)     4000000     ['input_17[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 49, 49, 32)   16416       ['input_18[0][0]']               \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 100, 100)    1712        ['embedding_7[0][0]',            \n",
            " eadAttention)                                                    'embedding_7[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 3, 3, 32)    0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  (None, 100)         45600       ['multi_head_attention_2[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)            (None, 288)          0           ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " tf.concat_6 (TFOpLambda)       (None, 388)          0           ['bidirectional_3[0][0]',        \n",
            "                                                                  'flatten_7[0][0]']              \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1167        ['tf.concat_6[0][0]']            \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           9336        ['tf.concat_6[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,074,231\n",
            "Trainable params: 4,074,231\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = bi_lstm_model.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'price': y_train_price,\n",
        "        'type': y_train_type,\n",
        "    },\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_genre_loss', patience=5, )\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lINOo9jVtfWm",
        "outputId": "e9b81dc9-b9d6-4dbb-8326-62ad0f8934ba"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 23.4600 - price_loss: 20.6101 - type_loss: 26.0404 - price_sparse_categorical_accuracy: 0.5102 - type_sparse_categorical_accuracy: 0.5806WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 41s 70ms/step - loss: 23.4600 - price_loss: 20.6101 - type_loss: 26.0404 - price_sparse_categorical_accuracy: 0.5102 - type_sparse_categorical_accuracy: 0.5806 - val_loss: 11.8080 - val_price_loss: 9.8340 - val_type_loss: 13.7544 - val_price_sparse_categorical_accuracy: 0.6206 - val_type_sparse_categorical_accuracy: 0.6664\n",
            "Epoch 2/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 7.2431 - price_loss: 4.8066 - type_loss: 9.6702 - price_sparse_categorical_accuracy: 0.5730 - type_sparse_categorical_accuracy: 0.6094WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 26s 68ms/step - loss: 7.2431 - price_loss: 4.8066 - type_loss: 9.6702 - price_sparse_categorical_accuracy: 0.5730 - type_sparse_categorical_accuracy: 0.6094 - val_loss: 5.4537 - val_price_loss: 4.6644 - val_type_loss: 6.2397 - val_price_sparse_categorical_accuracy: 0.5419 - val_type_sparse_categorical_accuracy: 0.6900\n",
            "Epoch 3/20\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.3606 - price_loss: 3.7566 - type_loss: 6.9601 - price_sparse_categorical_accuracy: 0.6152 - type_sparse_categorical_accuracy: 0.6243WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 5.3570 - price_loss: 3.7545 - type_loss: 6.9552 - price_sparse_categorical_accuracy: 0.6153 - type_sparse_categorical_accuracy: 0.6245 - val_loss: 7.4294 - val_price_loss: 5.3014 - val_type_loss: 9.5536 - val_price_sparse_categorical_accuracy: 0.5832 - val_type_sparse_categorical_accuracy: 0.6225\n",
            "Epoch 4/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.9888 - price_loss: 3.8667 - type_loss: 8.1030 - price_sparse_categorical_accuracy: 0.6294 - type_sparse_categorical_accuracy: 0.6268WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 27s 71ms/step - loss: 5.9888 - price_loss: 3.8667 - type_loss: 8.1030 - price_sparse_categorical_accuracy: 0.6294 - type_sparse_categorical_accuracy: 0.6268 - val_loss: 9.0746 - val_price_loss: 6.3988 - val_type_loss: 11.6988 - val_price_sparse_categorical_accuracy: 0.5990 - val_type_sparse_categorical_accuracy: 0.7516\n",
            "Epoch 5/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 9.2835 - price_loss: 5.1114 - type_loss: 13.4319 - price_sparse_categorical_accuracy: 0.6451 - type_sparse_categorical_accuracy: 0.6358WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 27s 70ms/step - loss: 9.2835 - price_loss: 5.1114 - type_loss: 13.4319 - price_sparse_categorical_accuracy: 0.6451 - type_sparse_categorical_accuracy: 0.6358 - val_loss: 9.9315 - val_price_loss: 4.6741 - val_type_loss: 15.1695 - val_price_sparse_categorical_accuracy: 0.5819 - val_type_sparse_categorical_accuracy: 0.2195\n",
            "Epoch 6/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 10.2838 - price_loss: 6.2901 - type_loss: 14.2367 - price_sparse_categorical_accuracy: 0.6738 - type_sparse_categorical_accuracy: 0.6353WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 27s 70ms/step - loss: 10.2838 - price_loss: 6.2901 - type_loss: 14.2367 - price_sparse_categorical_accuracy: 0.6738 - type_sparse_categorical_accuracy: 0.6353 - val_loss: 8.0421 - val_price_loss: 5.1424 - val_type_loss: 10.8727 - val_price_sparse_categorical_accuracy: 0.6376 - val_type_sparse_categorical_accuracy: 0.7169\n",
            "Epoch 7/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 8.3764 - price_loss: 4.1783 - type_loss: 12.5192 - price_sparse_categorical_accuracy: 0.6994 - type_sparse_categorical_accuracy: 0.6543WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 8.3764 - price_loss: 4.1783 - type_loss: 12.5192 - price_sparse_categorical_accuracy: 0.6994 - type_sparse_categorical_accuracy: 0.6543 - val_loss: 7.7808 - val_price_loss: 6.9147 - val_type_loss: 8.5879 - val_price_sparse_categorical_accuracy: 0.6370 - val_type_sparse_categorical_accuracy: 0.7189\n",
            "Epoch 8/20\n",
            "381/382 [============================>.] - ETA: 0s - loss: 4.0615 - price_loss: 2.5649 - type_loss: 5.5118 - price_sparse_categorical_accuracy: 0.7343 - type_sparse_categorical_accuracy: 0.6873WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 4.0625 - price_loss: 2.5630 - type_loss: 5.5157 - price_sparse_categorical_accuracy: 0.7343 - type_sparse_categorical_accuracy: 0.6871 - val_loss: 5.3938 - val_price_loss: 4.5935 - val_type_loss: 6.1585 - val_price_sparse_categorical_accuracy: 0.6481 - val_type_sparse_categorical_accuracy: 0.4817\n",
            "Epoch 9/20\n",
            "381/382 [============================>.] - ETA: 0s - loss: 4.0905 - price_loss: 2.4339 - type_loss: 5.7112 - price_sparse_categorical_accuracy: 0.7500 - type_sparse_categorical_accuracy: 0.6850WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 4.0996 - price_loss: 2.4416 - type_loss: 5.7218 - price_sparse_categorical_accuracy: 0.7497 - type_sparse_categorical_accuracy: 0.6846 - val_loss: 7.5188 - val_price_loss: 5.6416 - val_type_loss: 9.3601 - val_price_sparse_categorical_accuracy: 0.6081 - val_type_sparse_categorical_accuracy: 0.7536\n",
            "Epoch 10/20\n",
            "381/382 [============================>.] - ETA: 0s - loss: 4.0882 - price_loss: 2.4285 - type_loss: 5.7054 - price_sparse_categorical_accuracy: 0.7590 - type_sparse_categorical_accuracy: 0.6923WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 4.0940 - price_loss: 2.4265 - type_loss: 5.7190 - price_sparse_categorical_accuracy: 0.7592 - type_sparse_categorical_accuracy: 0.6920 - val_loss: 7.2089 - val_price_loss: 5.2628 - val_type_loss: 9.1176 - val_price_sparse_categorical_accuracy: 0.6422 - val_type_sparse_categorical_accuracy: 0.6206\n",
            "Epoch 11/20\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.0208 - price_loss: 3.3626 - type_loss: 6.6275 - price_sparse_categorical_accuracy: 0.7544 - type_sparse_categorical_accuracy: 0.6972WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 5.0174 - price_loss: 3.3609 - type_loss: 6.6223 - price_sparse_categorical_accuracy: 0.7545 - type_sparse_categorical_accuracy: 0.6973 - val_loss: 10.2340 - val_price_loss: 6.6373 - val_type_loss: 13.7626 - val_price_sparse_categorical_accuracy: 0.6232 - val_type_sparse_categorical_accuracy: 0.3545\n",
            "Epoch 12/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 6.1836 - price_loss: 3.4377 - type_loss: 8.8694 - price_sparse_categorical_accuracy: 0.7645 - type_sparse_categorical_accuracy: 0.6932WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 6.1836 - price_loss: 3.4377 - type_loss: 8.8694 - price_sparse_categorical_accuracy: 0.7645 - type_sparse_categorical_accuracy: 0.6932 - val_loss: 13.3090 - val_price_loss: 10.3776 - val_type_loss: 16.1670 - val_price_sparse_categorical_accuracy: 0.6468 - val_type_sparse_categorical_accuracy: 0.7176\n",
            "Epoch 13/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.1776 - price_loss: 2.6675 - type_loss: 7.6346 - price_sparse_categorical_accuracy: 0.7917 - type_sparse_categorical_accuracy: 0.7150WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 64ms/step - loss: 5.1776 - price_loss: 2.6675 - type_loss: 7.6346 - price_sparse_categorical_accuracy: 0.7917 - type_sparse_categorical_accuracy: 0.7150 - val_loss: 8.2297 - val_price_loss: 6.9372 - val_type_loss: 9.4737 - val_price_sparse_categorical_accuracy: 0.6632 - val_type_sparse_categorical_accuracy: 0.5603\n",
            "Epoch 14/20\n",
            "381/382 [============================>.] - ETA: 0s - loss: 13.0919 - price_loss: 6.9816 - type_loss: 19.1273 - price_sparse_categorical_accuracy: 0.7461 - type_sparse_categorical_accuracy: 0.6944WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 64ms/step - loss: 13.0842 - price_loss: 6.9782 - type_loss: 19.1152 - price_sparse_categorical_accuracy: 0.7459 - type_sparse_categorical_accuracy: 0.6941 - val_loss: 11.2851 - val_price_loss: 9.5837 - val_type_loss: 12.9012 - val_price_sparse_categorical_accuracy: 0.6383 - val_type_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 15/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 6.9449 - price_loss: 2.8334 - type_loss: 10.9855 - price_sparse_categorical_accuracy: 0.8118 - type_sparse_categorical_accuracy: 0.7328WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 6.9449 - price_loss: 2.8334 - type_loss: 10.9855 - price_sparse_categorical_accuracy: 0.8118 - type_sparse_categorical_accuracy: 0.7328 - val_loss: 10.0809 - val_price_loss: 7.3492 - val_type_loss: 12.7632 - val_price_sparse_categorical_accuracy: 0.5924 - val_type_sparse_categorical_accuracy: 0.7097\n",
            "Epoch 16/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 3.9655 - price_loss: 1.9539 - type_loss: 5.9319 - price_sparse_categorical_accuracy: 0.8369 - type_sparse_categorical_accuracy: 0.7594WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 3.9655 - price_loss: 1.9539 - type_loss: 5.9319 - price_sparse_categorical_accuracy: 0.8369 - type_sparse_categorical_accuracy: 0.7594 - val_loss: 8.0140 - val_price_loss: 7.9426 - val_type_loss: 8.0463 - val_price_sparse_categorical_accuracy: 0.6271 - val_type_sparse_categorical_accuracy: 0.7012\n",
            "Epoch 17/20\n",
            "381/382 [============================>.] - ETA: 0s - loss: 2.9983 - price_loss: 1.5650 - type_loss: 4.3966 - price_sparse_categorical_accuracy: 0.8481 - type_sparse_categorical_accuracy: 0.7748WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 2.9960 - price_loss: 1.5638 - type_loss: 4.3932 - price_sparse_categorical_accuracy: 0.8482 - type_sparse_categorical_accuracy: 0.7748 - val_loss: 6.5267 - val_price_loss: 6.7917 - val_type_loss: 6.2261 - val_price_sparse_categorical_accuracy: 0.6507 - val_type_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 18/20\n",
            "381/382 [============================>.] - ETA: 0s - loss: 3.0134 - price_loss: 1.6528 - type_loss: 4.3362 - price_sparse_categorical_accuracy: 0.8448 - type_sparse_categorical_accuracy: 0.7697WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 3.0113 - price_loss: 1.6514 - type_loss: 4.3333 - price_sparse_categorical_accuracy: 0.8449 - type_sparse_categorical_accuracy: 0.7697 - val_loss: 7.4958 - val_price_loss: 7.3338 - val_type_loss: 7.6213 - val_price_sparse_categorical_accuracy: 0.5760 - val_type_sparse_categorical_accuracy: 0.6710\n",
            "Epoch 19/20\n",
            "381/382 [============================>.] - ETA: 0s - loss: 7.2749 - price_loss: 3.4143 - type_loss: 11.0852 - price_sparse_categorical_accuracy: 0.8238 - type_sparse_categorical_accuracy: 0.7554WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 7.3073 - price_loss: 3.4116 - type_loss: 11.1527 - price_sparse_categorical_accuracy: 0.8240 - type_sparse_categorical_accuracy: 0.7554 - val_loss: 13.7035 - val_price_loss: 10.5702 - val_type_loss: 16.7723 - val_price_sparse_categorical_accuracy: 0.6114 - val_type_sparse_categorical_accuracy: 0.7117\n",
            "Epoch 20/20\n",
            "382/382 [==============================] - ETA: 0s - loss: 7.8686 - price_loss: 3.8469 - type_loss: 11.8003 - price_sparse_categorical_accuracy: 0.8095 - type_sparse_categorical_accuracy: 0.7394WARNING:tensorflow:Early stopping conditioned on metric `val_genre_loss` which is not available. Available metrics are: loss,price_loss,type_loss,price_sparse_categorical_accuracy,type_sparse_categorical_accuracy,val_loss,val_price_loss,val_type_loss,val_price_sparse_categorical_accuracy,val_type_sparse_categorical_accuracy\n",
            "382/382 [==============================] - 25s 65ms/step - loss: 7.8686 - price_loss: 3.8469 - type_loss: 11.8003 - price_sparse_categorical_accuracy: 0.8095 - type_sparse_categorical_accuracy: 0.7394 - val_loss: 10.8491 - val_price_loss: 10.3561 - val_type_loss: 11.2687 - val_price_sparse_categorical_accuracy: 0.6553 - val_type_sparse_categorical_accuracy: 0.6114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "y_predict_bi_lstm = bi_lstm_model.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_bi_lstm = y_predict_bi_lstm['price']\n",
        "print(price_predicted_bi_lstm)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_bi_lstm = np.argmax(price_predicted_bi_lstm, axis=1)\n",
        "print(price_category_predicted_bi_lstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgVU5g6RPJZW",
        "outputId": "cc83bf84-f0fd-408c-d936-5b2556f4827c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.3689743e-01 1.6310252e-01 9.1745195e-11]\n",
            " [1.0000000e+00 5.2706711e-25 0.0000000e+00]\n",
            " [1.0000000e+00 1.3710326e-13 7.7345496e-28]\n",
            " ...\n",
            " [1.0000000e+00 2.1827405e-10 4.9181348e-31]\n",
            " [1.0000000e+00 3.4206867e-26 0.0000000e+00]\n",
            " [2.2832235e-02 9.7716779e-01 1.8831327e-13]]\n",
            "[0 0 0 ... 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(\n",
        "    {'id': test.id,\n",
        "     'price': price_category_predicted_bi_lstm}\n",
        ").to_csv('sample_submission_bi_lstm.csv', index=False)"
      ],
      "metadata": {
        "id": "gFIRIul9ts-G"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 6"
      ],
      "metadata": {
        "id": "8E0aXzTSEWks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "thoughts and observations for trial 5: the performance didn't change the accuracy is still 0.58315\n",
        "\n",
        "plan for trial 5: Dropout, Rescaling and GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "ox0_McCoExZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MultiHeadAttention\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Rescaling\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "# simple average of embedding. you can change it to anything else as needed\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "\n",
        "# adding GRU layer after embedding layer and\n",
        "# this is the only difference than the LSTM\n",
        "attention = MultiHeadAttention(num_heads=2, key_dim=2)(embedded, embedded)\n",
        "bi_lstm = Bidirectional(GRU(50, recurrent_regularizer='l2'))(attention)\n",
        "\n",
        "\n",
        "scaling = Rescaling(1./127.5, offset=-1)(in_image) # rescaling\n",
        "pl = GlobalAveragePooling2D()(scaling) # global average pooling, pretty much the same as flattening\n",
        "do = Dropout(0.2)(pl) # dropout at a rate of 20%\n",
        "fl = Flatten()(do)\n",
        "\n",
        "# image part \n",
        "# simple conv2d. you can change it to anything else as needed\n",
        "cov = Conv2D(32, (16, 16))(in_image)\n",
        "pl = MaxPool2D((16, 16))(cov)\n",
        "flattened = Flatten()(pl)\n",
        "\n",
        "\n",
        "# fusion - combinig both\n",
        "fused = tf.concat([bi_lstm, flattened], axis=-1)\n",
        "\n",
        "# multi-task learning (each is a multi-class classification)\n",
        "# one dense layer for each task\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused)\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused)\n",
        "\n",
        "\n",
        "# define model input/output using keys.\n",
        "bi_lstm_model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# compile model with optimizer, loss values for each task, loss \n",
        "# weights for each task.\n",
        "bi_lstm_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "bi_lstm_model.summary()"
      ],
      "metadata": {
        "id": "yjaONRWpEYW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this model peoform the best as accuracy went up even better the the other model from 0.58315 to 0.65217"
      ],
      "metadata": {
        "id": "WkHxWRfuFQvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions "
      ],
      "metadata": {
        "id": "KZM86EUUFgFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Is fully-connected model a good one for sequential data? Why? How about for image data? Is it good? Why?\n",
        "\n",
        "fully connected networks make no assumptions about the input they tend to perform less and aren’t good for feature extraction. Plus they have a higher number of weights to train that results in high training time \n",
        "\n",
        "[Fully Connected](https://medium.com/swlh/fully-connected-vs-convolutional-neural-networks-813ca7bc6ee5)"
      ],
      "metadata": {
        "id": "r19BCFE0Fqcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is gradient vanishing and gradient explosion, and how GRU/LSTM tries to mitigate this problem?\n",
        "\n",
        "Vanishing gradient as backpropagation advances downwards from the output layer towards the input layers, the gradents often get smallerand smaller and approad to zero which leaves the weights of the initial layers nearly unchanged as a result the gradient descent never converge to the optimum\n",
        "\n",
        "explosion gradient: the gradients keep on getting larger and larger as backpropagation processes causes the gradient descent to diverge  \n",
        "\n",
        "How to mitigate the problem: using a unique additive gradient structure that includes direct access to the forget gate's activations, enabling the network to encourage desired behaviour from the error gradient using frequent gates update on every time step of the learning process.\n"
      ],
      "metadata": {
        "id": "rRC-ESTSFx-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What is multi-objective/multi-task learning? What is multi-modality learning? How do you use them in this assignment?\n",
        "\n",
        "The world surrounding us involves multiple modalities – we see objects, hear sounds, feel texture, smell odors, and so on. In general terms, a modality refers to the way in which something happens or is experienced [1]. Multi-Modality learning leverages the information from different source of information to make informed predictions\n",
        "\n",
        "multi-objective: where I have multiple tasking in the same problem her we have text and images \n",
        "\n",
        "multi-modality: represent these tasks with numerical numbers that try to mitigate these tasks as much as possible\n",
        "\n",
        "in this assignment: I used text and images to predict the price range which is normally a regression problem but using multi-modality we turned it to classification"
      ],
      "metadata": {
        "id": "fyh39jKHI6RC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What is the difference among xgboost, lightgbm and catboost\n",
        "\n",
        "a trained CatBoost tree can predict extraordinarily faster than either XGBoost or LightGBM and it is designed for categorical data and is known to have the best performance on it, showing the state-of-the-art performance over XGBoost and LightGBM\n",
        "\n",
        "XGBoost has been around the block longer than either LightGBM and CatBoost, so it has better learning resources and a more active developer community. "
      ],
      "metadata": {
        "id": "Dv6VZrJEKtn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RK9qi3wvFw1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###References\n",
        "I have used the lab and GavinMc Clelland work as a guide to overcome my problems of the past assignments\n",
        "\n",
        "[LAB](https://colab.research.google.com/drive/1Fk6xXp10o-fwECMduXBtLJE_1ZZ-GrlO)\n",
        "\n",
        "[GitHub GavinMcClelland](https://github.com/gavinmcclelland/CISC-873/blob/main/a4-airbnb-price-categorization/CISC_873_A4_2021_GavinMcClelland_10211444.ipynb)"
      ],
      "metadata": {
        "id": "zumSrgZgLaXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RXtyz3HVL8_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Airbnb price category prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bba01d9147d486e94acdd4fc4819d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59428197821243bca96420891aeddec3",
              "IPY_MODEL_018a23b301254fc882f578191308e2ca",
              "IPY_MODEL_b720f43fd7eb4de683dbb20e62456296"
            ],
            "layout": "IPY_MODEL_293654a4a79542fcafd8e06c82a72606"
          }
        },
        "59428197821243bca96420891aeddec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9f2c9cdec614e4f927d2d952a541618",
            "placeholder": "​",
            "style": "IPY_MODEL_67f40f780bbc41eaa5d910108fdfee42",
            "value": "100%"
          }
        },
        "018a23b301254fc882f578191308e2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_236012a2084349a7882094631fae1d90",
            "max": 6101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5847317f659c4fb490bd36907f634b4d",
            "value": 6101
          }
        },
        "b720f43fd7eb4de683dbb20e62456296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f1b72c8632e41f8bd3d26e80791256f",
            "placeholder": "​",
            "style": "IPY_MODEL_35ecc7d7fefb44bd9e637d2b06d60431",
            "value": " 6101/6101 [01:06&lt;00:00, 95.20it/s]"
          }
        },
        "293654a4a79542fcafd8e06c82a72606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9f2c9cdec614e4f927d2d952a541618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f40f780bbc41eaa5d910108fdfee42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "236012a2084349a7882094631fae1d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5847317f659c4fb490bd36907f634b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f1b72c8632e41f8bd3d26e80791256f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35ecc7d7fefb44bd9e637d2b06d60431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6f35e5ad25945f6bb0330fd2b8a4ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2de7f8ff2cbe4143aab02086dafe969c",
              "IPY_MODEL_668daa5188ac435798c2555e2491baf7",
              "IPY_MODEL_65df93313bb740c39edda684914e462f"
            ],
            "layout": "IPY_MODEL_370b6bb362214e97a6d3284f7581be59"
          }
        },
        "2de7f8ff2cbe4143aab02086dafe969c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c253f2f96c54446a8cd27dea21c85fab",
            "placeholder": "​",
            "style": "IPY_MODEL_b5e039419ae24d0abf98896869365aba",
            "value": "100%"
          }
        },
        "668daa5188ac435798c2555e2491baf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_866821b385dd4df485cbd9adaa0d2297",
            "max": 7627,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_249f8217e1d94144b22de31e2c0e0864",
            "value": 7627
          }
        },
        "65df93313bb740c39edda684914e462f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d2cc6c7f5924a6e8a943b011ab15c59",
            "placeholder": "​",
            "style": "IPY_MODEL_cd161faf40634164b1863bc979cbff2a",
            "value": " 7627/7627 [01:31&lt;00:00, 95.96it/s]"
          }
        },
        "370b6bb362214e97a6d3284f7581be59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c253f2f96c54446a8cd27dea21c85fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e039419ae24d0abf98896869365aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "866821b385dd4df485cbd9adaa0d2297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249f8217e1d94144b22de31e2c0e0864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d2cc6c7f5924a6e8a943b011ab15c59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd161faf40634164b1863bc979cbff2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aafead4ec66145c7aaebc62392d9b033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9178aea6abc0464ea57d4c3ad238bb36",
              "IPY_MODEL_3f83ae07308345ceb839087398b55663",
              "IPY_MODEL_6e0b10fc091c468d84d36e9163560cd7"
            ],
            "layout": "IPY_MODEL_0888aadbf917498890fab3b5e6130e67"
          }
        },
        "9178aea6abc0464ea57d4c3ad238bb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_405ac1bc6dab4146b184b375635c1b75",
            "placeholder": "​",
            "style": "IPY_MODEL_786b0ddc35714c36b8ec1976d6c655e6",
            "value": "100%"
          }
        },
        "3f83ae07308345ceb839087398b55663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_058403f64c1d4749bf8ceaa59dc0092b",
            "max": 7360,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ba146b343aa42498a5bcf3faf261ba2",
            "value": 7360
          }
        },
        "6e0b10fc091c468d84d36e9163560cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61ef24ab89524ce48c45a203f5b4e2e3",
            "placeholder": "​",
            "style": "IPY_MODEL_770c9957c0914ea1b8a4ef4c6edaf00f",
            "value": " 7360/7360 [01:21&lt;00:00, 93.72it/s]"
          }
        },
        "0888aadbf917498890fab3b5e6130e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405ac1bc6dab4146b184b375635c1b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "786b0ddc35714c36b8ec1976d6c655e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "058403f64c1d4749bf8ceaa59dc0092b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba146b343aa42498a5bcf3faf261ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61ef24ab89524ce48c45a203f5b4e2e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "770c9957c0914ea1b8a4ef4c6edaf00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}